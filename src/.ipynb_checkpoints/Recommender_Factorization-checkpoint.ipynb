{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "# import scipy\n",
    "# import scipy.io\n",
    "# import scipy.sparse as sp\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_dir = '../data/'\n",
    "sub_dir = '../submit/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "Note that `ratings` is a sparse matrix that in the shape of (num_items, num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 1000, number of users: 10000\n",
      "number of items: 1000, number of users: 10000\n",
      "(1000, 10000)\n"
     ]
    }
   ],
   "source": [
    "from pre_post_process import *\n",
    "\n",
    "_, ratings = load_data(dat_dir + \"data_train.csv\")\n",
    "sample_ids, _ = load_data(dat_dir + \"sample_submission.csv\")\n",
    "print(np.shape(ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 43),\n",
       " (0, 60),\n",
       " (0, 66),\n",
       " (0, 71),\n",
       " (0, 85),\n",
       " (0, 89),\n",
       " (0, 107),\n",
       " (0, 113),\n",
       " (0, 119),\n",
       " (0, 134),\n",
       " (0, 151),\n",
       " (0, 164),\n",
       " (0, 181),\n",
       " (0, 309),\n",
       " (0, 317),\n",
       " (0, 332),\n",
       " (0, 354),\n",
       " (0, 389),\n",
       " (0, 400),\n",
       " (0, 409),\n",
       " (0, 417),\n",
       " (0, 456),\n",
       " (0, 469),\n",
       " (0, 496),\n",
       " (0, 515),\n",
       " (0, 565),\n",
       " (0, 594),\n",
       " (0, 669),\n",
       " (0, 672),\n",
       " (0, 707),\n",
       " (0, 719),\n",
       " (0, 742),\n",
       " (0, 776),\n",
       " (0, 860),\n",
       " (0, 871),\n",
       " (0, 907),\n",
       " (0, 929),\n",
       " (0, 965),\n",
       " (0, 966),\n",
       " (0, 980),\n",
       " (0, 1033),\n",
       " (0, 1074),\n",
       " (0, 1106),\n",
       " (0, 1219),\n",
       " (0, 1229),\n",
       " (0, 1253),\n",
       " (0, 1337),\n",
       " (0, 1406),\n",
       " (0, 1434),\n",
       " (0, 1488),\n",
       " (0, 1494),\n",
       " (0, 1526),\n",
       " (0, 1546),\n",
       " (0, 1548),\n",
       " (0, 1569),\n",
       " (0, 1582),\n",
       " (0, 1621),\n",
       " (0, 1666),\n",
       " (0, 1774),\n",
       " (0, 1788),\n",
       " (0, 1801),\n",
       " (0, 1812),\n",
       " (0, 1829),\n",
       " (0, 1849),\n",
       " (0, 1877),\n",
       " (0, 1920),\n",
       " (0, 1969),\n",
       " (0, 2037),\n",
       " (0, 2050),\n",
       " (0, 2080),\n",
       " (0, 2089),\n",
       " (0, 2096),\n",
       " (0, 2106),\n",
       " (0, 2175),\n",
       " (0, 2194),\n",
       " (0, 2224),\n",
       " (0, 2243),\n",
       " (0, 2283),\n",
       " (0, 2326),\n",
       " (0, 2346),\n",
       " (0, 2356),\n",
       " (0, 2359),\n",
       " (0, 2382),\n",
       " (0, 2400),\n",
       " (0, 2427),\n",
       " (0, 2445),\n",
       " (0, 2475),\n",
       " (0, 2478),\n",
       " (0, 2481),\n",
       " (0, 2517),\n",
       " (0, 2525),\n",
       " (0, 2571),\n",
       " (0, 2622),\n",
       " (0, 2670),\n",
       " (0, 2680),\n",
       " (0, 2705),\n",
       " (0, 2819),\n",
       " (0, 2882),\n",
       " (0, 2938),\n",
       " (0, 2941),\n",
       " (0, 2969),\n",
       " (0, 2982),\n",
       " (0, 3068),\n",
       " (0, 3099),\n",
       " (0, 3108),\n",
       " (0, 3129),\n",
       " (0, 3134),\n",
       " (0, 3160),\n",
       " (0, 3188),\n",
       " (0, 3198),\n",
       " (0, 3313),\n",
       " (0, 3320),\n",
       " (0, 3330),\n",
       " (0, 3356),\n",
       " (0, 3381),\n",
       " (0, 3414),\n",
       " (0, 3435),\n",
       " (0, 3494),\n",
       " (0, 3508),\n",
       " (0, 3533),\n",
       " (0, 3622),\n",
       " (0, 3652),\n",
       " (0, 3656),\n",
       " (0, 3673),\n",
       " (0, 3774),\n",
       " (0, 3821),\n",
       " (0, 3929),\n",
       " (0, 3946),\n",
       " (0, 3951),\n",
       " (0, 3995),\n",
       " (0, 4060),\n",
       " (0, 4140),\n",
       " (0, 4145),\n",
       " (0, 4201),\n",
       " (0, 4217),\n",
       " (0, 4310),\n",
       " (0, 4329),\n",
       " (0, 4340),\n",
       " (0, 4374),\n",
       " (0, 4404),\n",
       " (0, 4408),\n",
       " (0, 4523),\n",
       " (0, 4529),\n",
       " (0, 4550),\n",
       " (0, 4599),\n",
       " (0, 4606),\n",
       " (0, 4610),\n",
       " (0, 4758),\n",
       " (0, 4763),\n",
       " (0, 4769),\n",
       " (0, 4833),\n",
       " (0, 4853),\n",
       " (0, 4889),\n",
       " (0, 4943),\n",
       " (0, 5001),\n",
       " (0, 5012),\n",
       " (0, 5019),\n",
       " (0, 5041),\n",
       " (0, 5062),\n",
       " (0, 5092),\n",
       " (0, 5099),\n",
       " (0, 5100),\n",
       " (0, 5103),\n",
       " (0, 5115),\n",
       " (0, 5149),\n",
       " (0, 5152),\n",
       " (0, 5193),\n",
       " (0, 5270),\n",
       " (0, 5288),\n",
       " (0, 5307),\n",
       " (0, 5315),\n",
       " (0, 5386),\n",
       " (0, 5405),\n",
       " (0, 5407),\n",
       " (0, 5410),\n",
       " (0, 5418),\n",
       " (0, 5425),\n",
       " (0, 5430),\n",
       " (0, 5432),\n",
       " (0, 5444),\n",
       " (0, 5454),\n",
       " (0, 5511),\n",
       " (0, 5579),\n",
       " (0, 5587),\n",
       " (0, 5617),\n",
       " (0, 5662),\n",
       " (0, 5748),\n",
       " (0, 5771),\n",
       " (0, 5863),\n",
       " (0, 5901),\n",
       " (0, 5937),\n",
       " (0, 5976),\n",
       " (0, 5978),\n",
       " (0, 5985),\n",
       " (0, 6002),\n",
       " (0, 6023),\n",
       " (0, 6029),\n",
       " (0, 6056),\n",
       " (0, 6075),\n",
       " (0, 6094),\n",
       " (0, 6179),\n",
       " (0, 6218),\n",
       " (0, 6221),\n",
       " (0, 6235),\n",
       " (0, 6241),\n",
       " (0, 6387),\n",
       " (0, 6401),\n",
       " (0, 6410),\n",
       " (0, 6418),\n",
       " (0, 6441),\n",
       " (0, 6462),\n",
       " (0, 6506),\n",
       " (0, 6597),\n",
       " (0, 6605),\n",
       " (0, 6735),\n",
       " (0, 6760),\n",
       " (0, 6766),\n",
       " (0, 6771),\n",
       " (0, 6861),\n",
       " (0, 6886),\n",
       " (0, 6902),\n",
       " (0, 6937),\n",
       " (0, 6953),\n",
       " (0, 6965),\n",
       " (0, 6979),\n",
       " (0, 7013),\n",
       " (0, 7026),\n",
       " (0, 7054),\n",
       " (0, 7077),\n",
       " (0, 7096),\n",
       " (0, 7103),\n",
       " (0, 7113),\n",
       " (0, 7206),\n",
       " (0, 7213),\n",
       " (0, 7248),\n",
       " (0, 7256),\n",
       " (0, 7305),\n",
       " (0, 7379),\n",
       " (0, 7458),\n",
       " (0, 7489),\n",
       " (0, 7491),\n",
       " (0, 7548),\n",
       " (0, 7557),\n",
       " (0, 7567),\n",
       " (0, 7668),\n",
       " (0, 7718),\n",
       " (0, 7787),\n",
       " (0, 7827),\n",
       " (0, 7854),\n",
       " (0, 7856),\n",
       " (0, 7858),\n",
       " (0, 7874),\n",
       " (0, 7921),\n",
       " (0, 7958),\n",
       " (0, 7972),\n",
       " (0, 7988),\n",
       " (0, 8005),\n",
       " (0, 8070),\n",
       " (0, 8179),\n",
       " (0, 8197),\n",
       " (0, 8209),\n",
       " (0, 8217),\n",
       " (0, 8221),\n",
       " (0, 8232),\n",
       " (0, 8244),\n",
       " (0, 8250),\n",
       " (0, 8286),\n",
       " (0, 8318),\n",
       " (0, 8358),\n",
       " (0, 8369),\n",
       " (0, 8376),\n",
       " (0, 8377),\n",
       " (0, 8400),\n",
       " (0, 8408),\n",
       " (0, 8436),\n",
       " (0, 8473),\n",
       " (0, 8474),\n",
       " (0, 8500),\n",
       " (0, 8641),\n",
       " (0, 8652),\n",
       " (0, 8679),\n",
       " (0, 8698),\n",
       " (0, 8705),\n",
       " (0, 8715),\n",
       " (0, 8741),\n",
       " (0, 8785),\n",
       " (0, 8803),\n",
       " (0, 8812),\n",
       " (0, 8827),\n",
       " (0, 8854),\n",
       " (0, 8858),\n",
       " (0, 8904),\n",
       " (0, 8921),\n",
       " (0, 8932),\n",
       " (0, 8957),\n",
       " (0, 8994),\n",
       " (0, 9028),\n",
       " (0, 9103),\n",
       " (0, 9104),\n",
       " (0, 9107),\n",
       " (0, 9139),\n",
       " (0, 9146),\n",
       " (0, 9150),\n",
       " (0, 9170),\n",
       " (0, 9182),\n",
       " (0, 9197),\n",
       " (0, 9223),\n",
       " (0, 9229),\n",
       " (0, 9263),\n",
       " (0, 9264),\n",
       " (0, 9299),\n",
       " (0, 9330),\n",
       " (0, 9376),\n",
       " (0, 9385),\n",
       " (0, 9391),\n",
       " (0, 9452),\n",
       " (0, 9454),\n",
       " (0, 9462),\n",
       " (0, 9485),\n",
       " (0, 9519),\n",
       " (0, 9538),\n",
       " (0, 9540),\n",
       " (0, 9599),\n",
       " (0, 9615),\n",
       " (0, 9640),\n",
       " (0, 9641),\n",
       " (0, 9655),\n",
       " (0, 9689),\n",
       " (0, 9708),\n",
       " (0, 9787),\n",
       " (0, 9798),\n",
       " (0, 9800),\n",
       " (0, 9815),\n",
       " (0, 9816),\n",
       " (0, 9846),\n",
       " (0, 9872),\n",
       " (0, 9909),\n",
       " (0, 9931),\n",
       " (0, 9963),\n",
       " (0, 9991),\n",
       " (1, 4),\n",
       " (1, 13),\n",
       " (1, 24),\n",
       " (1, 40),\n",
       " (1, 43),\n",
       " (1, 61),\n",
       " (1, 78),\n",
       " (1, 86),\n",
       " (1, 119),\n",
       " (1, 134),\n",
       " (1, 142),\n",
       " (1, 151),\n",
       " (1, 159),\n",
       " (1, 164),\n",
       " (1, 227),\n",
       " (1, 229),\n",
       " (1, 240),\n",
       " (1, 247),\n",
       " (1, 256),\n",
       " (1, 259),\n",
       " (1, 301),\n",
       " (1, 370),\n",
       " (1, 393),\n",
       " (1, 400),\n",
       " (1, 402),\n",
       " (1, 409),\n",
       " (1, 432),\n",
       " (1, 486),\n",
       " (1, 498),\n",
       " (1, 516),\n",
       " (1, 551),\n",
       " (1, 587),\n",
       " (1, 606),\n",
       " (1, 608),\n",
       " (1, 627),\n",
       " (1, 641),\n",
       " (1, 651),\n",
       " (1, 689),\n",
       " (1, 735),\n",
       " (1, 742),\n",
       " (1, 747),\n",
       " (1, 773),\n",
       " (1, 792),\n",
       " (1, 809),\n",
       " (1, 886),\n",
       " (1, 911),\n",
       " (1, 913),\n",
       " (1, 934),\n",
       " (1, 950),\n",
       " (1, 996),\n",
       " (1, 999),\n",
       " (1, 1072),\n",
       " (1, 1095),\n",
       " (1, 1097),\n",
       " (1, 1122),\n",
       " (1, 1164),\n",
       " (1, 1190),\n",
       " (1, 1223),\n",
       " (1, 1226),\n",
       " (1, 1232),\n",
       " (1, 1280),\n",
       " (1, 1288),\n",
       " (1, 1318),\n",
       " (1, 1322),\n",
       " (1, 1365),\n",
       " (1, 1387),\n",
       " (1, 1392),\n",
       " (1, 1397),\n",
       " (1, 1417),\n",
       " (1, 1437),\n",
       " (1, 1442),\n",
       " (1, 1480),\n",
       " (1, 1522),\n",
       " (1, 1523),\n",
       " (1, 1525),\n",
       " (1, 1546),\n",
       " (1, 1549),\n",
       " (1, 1557),\n",
       " (1, 1615),\n",
       " (1, 1622),\n",
       " (1, 1635),\n",
       " (1, 1710),\n",
       " (1, 1726),\n",
       " (1, 1762),\n",
       " (1, 1787),\n",
       " (1, 1788),\n",
       " (1, 1829),\n",
       " (1, 1858),\n",
       " (1, 1920),\n",
       " (1, 1921),\n",
       " (1, 1948),\n",
       " (1, 1972),\n",
       " (1, 1982),\n",
       " (1, 2011),\n",
       " (1, 2028),\n",
       " (1, 2046),\n",
       " (1, 2048),\n",
       " (1, 2061),\n",
       " (1, 2082),\n",
       " (1, 2083),\n",
       " (1, 2119),\n",
       " (1, 2122),\n",
       " (1, 2124),\n",
       " (1, 2137),\n",
       " (1, 2159),\n",
       " (1, 2162),\n",
       " (1, 2195),\n",
       " (1, 2200),\n",
       " (1, 2205),\n",
       " (1, 2254),\n",
       " (1, 2267),\n",
       " (1, 2280),\n",
       " (1, 2286),\n",
       " (1, 2294),\n",
       " (1, 2333),\n",
       " (1, 2356),\n",
       " (1, 2372),\n",
       " (1, 2392),\n",
       " (1, 2434),\n",
       " (1, 2457),\n",
       " (1, 2485),\n",
       " (1, 2493),\n",
       " (1, 2502),\n",
       " (1, 2511),\n",
       " (1, 2529),\n",
       " (1, 2536),\n",
       " (1, 2548),\n",
       " (1, 2552),\n",
       " (1, 2589),\n",
       " (1, 2590),\n",
       " (1, 2653),\n",
       " (1, 2654),\n",
       " (1, 2655),\n",
       " (1, 2681),\n",
       " (1, 2686),\n",
       " (1, 2687),\n",
       " (1, 2705),\n",
       " (1, 2722),\n",
       " (1, 2728),\n",
       " (1, 2742),\n",
       " (1, 2777),\n",
       " (1, 2781),\n",
       " (1, 2793),\n",
       " (1, 2797),\n",
       " (1, 2803),\n",
       " (1, 2827),\n",
       " (1, 2829),\n",
       " (1, 2846),\n",
       " (1, 2943),\n",
       " (1, 2949),\n",
       " (1, 3000),\n",
       " (1, 3005),\n",
       " (1, 3017),\n",
       " (1, 3102),\n",
       " (1, 3123),\n",
       " (1, 3138),\n",
       " (1, 3155),\n",
       " (1, 3161),\n",
       " (1, 3173),\n",
       " (1, 3198),\n",
       " (1, 3260),\n",
       " (1, 3267),\n",
       " (1, 3268),\n",
       " (1, 3277),\n",
       " (1, 3287),\n",
       " (1, 3302),\n",
       " (1, 3306),\n",
       " (1, 3319),\n",
       " (1, 3356),\n",
       " (1, 3362),\n",
       " (1, 3365),\n",
       " (1, 3381),\n",
       " (1, 3383),\n",
       " (1, 3419),\n",
       " (1, 3490),\n",
       " (1, 3499),\n",
       " (1, 3532),\n",
       " (1, 3536),\n",
       " (1, 3543),\n",
       " (1, 3547),\n",
       " (1, 3601),\n",
       " (1, 3649),\n",
       " (1, 3713),\n",
       " (1, 3723),\n",
       " (1, 3725),\n",
       " (1, 3731),\n",
       " (1, 3770),\n",
       " (1, 3796),\n",
       " (1, 3827),\n",
       " (1, 3828),\n",
       " (1, 3876),\n",
       " (1, 3902),\n",
       " (1, 3918),\n",
       " (1, 3962),\n",
       " (1, 3973),\n",
       " (1, 3985),\n",
       " (1, 3987),\n",
       " (1, 4022),\n",
       " (1, 4026),\n",
       " (1, 4089),\n",
       " (1, 4094),\n",
       " (1, 4099),\n",
       " (1, 4112),\n",
       " (1, 4114),\n",
       " (1, 4116),\n",
       " (1, 4136),\n",
       " (1, 4188),\n",
       " (1, 4197),\n",
       " (1, 4233),\n",
       " (1, 4238),\n",
       " (1, 4291),\n",
       " (1, 4292),\n",
       " (1, 4293),\n",
       " (1, 4296),\n",
       " (1, 4308),\n",
       " (1, 4310),\n",
       " (1, 4312),\n",
       " (1, 4323),\n",
       " (1, 4324),\n",
       " (1, 4360),\n",
       " (1, 4367),\n",
       " (1, 4368),\n",
       " (1, 4401),\n",
       " (1, 4433),\n",
       " (1, 4468),\n",
       " (1, 4475),\n",
       " (1, 4486),\n",
       " (1, 4526),\n",
       " (1, 4610),\n",
       " (1, 4628),\n",
       " (1, 4655),\n",
       " (1, 4737),\n",
       " (1, 4793),\n",
       " (1, 4822),\n",
       " (1, 4840),\n",
       " (1, 4866),\n",
       " (1, 4877),\n",
       " (1, 4916),\n",
       " (1, 4919),\n",
       " (1, 4950),\n",
       " (1, 4951),\n",
       " (1, 4958),\n",
       " (1, 4999),\n",
       " (1, 5006),\n",
       " (1, 5009),\n",
       " (1, 5015),\n",
       " (1, 5025),\n",
       " (1, 5059),\n",
       " (1, 5100),\n",
       " (1, 5101),\n",
       " (1, 5128),\n",
       " (1, 5166),\n",
       " (1, 5288),\n",
       " (1, 5311),\n",
       " (1, 5313),\n",
       " (1, 5315),\n",
       " (1, 5317),\n",
       " (1, 5381),\n",
       " (1, 5382),\n",
       " (1, 5401),\n",
       " (1, 5405),\n",
       " (1, 5410),\n",
       " (1, 5417),\n",
       " (1, 5432),\n",
       " (1, 5470),\n",
       " (1, 5490),\n",
       " (1, 5504),\n",
       " (1, 5511),\n",
       " (1, 5547),\n",
       " (1, 5560),\n",
       " (1, 5581),\n",
       " (1, 5602),\n",
       " (1, 5607),\n",
       " (1, 5623),\n",
       " (1, 5632),\n",
       " (1, 5684),\n",
       " (1, 5690),\n",
       " (1, 5698),\n",
       " (1, 5704),\n",
       " (1, 5727),\n",
       " (1, 5760),\n",
       " (1, 5771),\n",
       " (1, 5789),\n",
       " (1, 5792),\n",
       " (1, 5818),\n",
       " (1, 5822),\n",
       " (1, 5823),\n",
       " (1, 5828),\n",
       " (1, 5840),\n",
       " (1, 5855),\n",
       " (1, 5864),\n",
       " (1, 5880),\n",
       " (1, 5888),\n",
       " (1, 5917),\n",
       " (1, 5922),\n",
       " (1, 5948),\n",
       " (1, 5976),\n",
       " (1, 6008),\n",
       " (1, 6011),\n",
       " (1, 6013),\n",
       " (1, 6049),\n",
       " (1, 6083),\n",
       " (1, 6115),\n",
       " (1, 6116),\n",
       " (1, 6141),\n",
       " (1, 6149),\n",
       " (1, 6169),\n",
       " (1, 6221),\n",
       " (1, 6230),\n",
       " (1, 6249),\n",
       " (1, 6263),\n",
       " (1, 6272),\n",
       " (1, 6282),\n",
       " (1, 6292),\n",
       " (1, 6298),\n",
       " (1, 6302),\n",
       " (1, 6324),\n",
       " (1, 6335),\n",
       " (1, 6339),\n",
       " (1, 6342),\n",
       " (1, 6343),\n",
       " (1, 6400),\n",
       " (1, 6433),\n",
       " (1, 6437),\n",
       " (1, 6449),\n",
       " (1, 6478),\n",
       " (1, 6481),\n",
       " (1, 6505),\n",
       " (1, 6508),\n",
       " (1, 6525),\n",
       " (1, 6534),\n",
       " (1, 6536),\n",
       " (1, 6549),\n",
       " (1, 6560),\n",
       " (1, 6580),\n",
       " (1, 6670),\n",
       " (1, 6708),\n",
       " (1, 6709),\n",
       " (1, 6735),\n",
       " (1, 6757),\n",
       " (1, 6763),\n",
       " (1, 6772),\n",
       " (1, 6780),\n",
       " (1, 6798),\n",
       " (1, 6827),\n",
       " (1, 6834),\n",
       " (1, 6899),\n",
       " (1, 6905),\n",
       " (1, 6914),\n",
       " (1, 6934),\n",
       " (1, 6937),\n",
       " (1, 6955),\n",
       " (1, 6959),\n",
       " (1, 6994),\n",
       " (1, 6996),\n",
       " (1, 7000),\n",
       " (1, 7004),\n",
       " (1, 7039),\n",
       " (1, 7085),\n",
       " (1, 7119),\n",
       " (1, 7161),\n",
       " (1, 7164),\n",
       " (1, 7173),\n",
       " (1, 7175),\n",
       " (1, 7178),\n",
       " (1, 7196),\n",
       " (1, 7212),\n",
       " (1, 7235),\n",
       " (1, 7237),\n",
       " (1, 7270),\n",
       " (1, 7279),\n",
       " (1, 7280),\n",
       " (1, 7312),\n",
       " (1, 7334),\n",
       " (1, 7342),\n",
       " (1, 7354),\n",
       " (1, 7398),\n",
       " (1, 7442),\n",
       " (1, 7466),\n",
       " (1, 7474),\n",
       " (1, 7479),\n",
       " (1, 7494),\n",
       " (1, 7516),\n",
       " (1, 7524),\n",
       " (1, 7539),\n",
       " (1, 7560),\n",
       " (1, 7563),\n",
       " (1, 7568),\n",
       " (1, 7629),\n",
       " (1, 7650),\n",
       " (1, 7659),\n",
       " (1, 7660),\n",
       " (1, 7727),\n",
       " (1, 7756),\n",
       " (1, 7757),\n",
       " (1, 7769),\n",
       " (1, 7810),\n",
       " (1, 7826),\n",
       " (1, 7828),\n",
       " (1, 7832),\n",
       " (1, 7852),\n",
       " (1, 7874),\n",
       " (1, 7877),\n",
       " (1, 7909),\n",
       " (1, 7917),\n",
       " (1, 7943),\n",
       " (1, 7972),\n",
       " (1, 7983),\n",
       " (1, 8001),\n",
       " (1, 8016),\n",
       " (1, 8034),\n",
       " (1, 8070),\n",
       " (1, 8074),\n",
       " (1, 8078),\n",
       " (1, 8096),\n",
       " (1, 8100),\n",
       " (1, 8164),\n",
       " (1, 8188),\n",
       " (1, 8223),\n",
       " (1, 8227),\n",
       " (1, 8235),\n",
       " (1, 8241),\n",
       " (1, 8266),\n",
       " (1, 8268),\n",
       " (1, 8279),\n",
       " (1, 8283),\n",
       " (1, 8287),\n",
       " (1, 8297),\n",
       " (1, 8306),\n",
       " (1, 8333),\n",
       " (1, 8341),\n",
       " (1, 8358),\n",
       " (1, 8379),\n",
       " (1, 8388),\n",
       " (1, 8397),\n",
       " (1, 8400),\n",
       " (1, 8402),\n",
       " (1, 8410),\n",
       " (1, 8416),\n",
       " (1, 8436),\n",
       " (1, 8445),\n",
       " (1, 8464),\n",
       " (1, 8467),\n",
       " (1, 8503),\n",
       " (1, 8517),\n",
       " (1, 8535),\n",
       " (1, 8558),\n",
       " (1, 8570),\n",
       " (1, 8590),\n",
       " (1, 8616),\n",
       " (1, 8620),\n",
       " (1, 8652),\n",
       " (1, 8668),\n",
       " (1, 8686),\n",
       " (1, 8692),\n",
       " (1, 8696),\n",
       " (1, 8716),\n",
       " (1, 8747),\n",
       " (1, 8752),\n",
       " (1, 8762),\n",
       " (1, 8770),\n",
       " (1, 8783),\n",
       " (1, 8819),\n",
       " (1, 8832),\n",
       " (1, 8861),\n",
       " (1, 8904),\n",
       " (1, 8921),\n",
       " (1, 8951),\n",
       " (1, 8968),\n",
       " (1, 8980),\n",
       " (1, 8986),\n",
       " (1, 9007),\n",
       " (1, 9008),\n",
       " (1, 9011),\n",
       " (1, 9045),\n",
       " (1, 9083),\n",
       " (1, 9101),\n",
       " (1, 9110),\n",
       " (1, 9117),\n",
       " (1, 9155),\n",
       " (1, 9163),\n",
       " (1, 9187),\n",
       " (1, 9192),\n",
       " (1, 9237),\n",
       " (1, 9245),\n",
       " (1, 9247),\n",
       " (1, 9273),\n",
       " (1, 9275),\n",
       " (1, 9279),\n",
       " (1, 9297),\n",
       " (1, 9342),\n",
       " (1, 9391),\n",
       " (1, 9392),\n",
       " (1, 9406),\n",
       " (1, 9413),\n",
       " (1, 9429),\n",
       " (1, 9432),\n",
       " (1, 9439),\n",
       " (1, 9461),\n",
       " (1, 9493),\n",
       " (1, 9499),\n",
       " (1, 9504),\n",
       " (1, 9534),\n",
       " (1, 9538),\n",
       " (1, 9562),\n",
       " (1, 9586),\n",
       " (1, 9590),\n",
       " (1, 9617),\n",
       " (1, 9659),\n",
       " (1, 9660),\n",
       " (1, 9667),\n",
       " (1, 9682),\n",
       " (1, 9689),\n",
       " (1, 9702),\n",
       " (1, 9709),\n",
       " (1, 9710),\n",
       " (1, 9727),\n",
       " (1, 9733),\n",
       " (1, 9750),\n",
       " (1, 9762),\n",
       " (1, 9770),\n",
       " (1, 9820),\n",
       " (1, 9837),\n",
       " (1, 9839),\n",
       " (1, 9853),\n",
       " (1, 9874),\n",
       " (1, 9931),\n",
       " (1, 9935),\n",
       " (1, 9938),\n",
       " (1, 9967),\n",
       " (1, 9970),\n",
       " (2, 12),\n",
       " (2, 15),\n",
       " (2, 44),\n",
       " (2, 46),\n",
       " (2, 56),\n",
       " (2, 61),\n",
       " (2, 69),\n",
       " (2, 70),\n",
       " (2, 80),\n",
       " (2, 99),\n",
       " (2, 103),\n",
       " (2, 110),\n",
       " (2, 119),\n",
       " (2, 134),\n",
       " (2, 143),\n",
       " (2, 153),\n",
       " (2, 161),\n",
       " (2, 194),\n",
       " (2, 196),\n",
       " (2, 198),\n",
       " (2, 202),\n",
       " (2, 245),\n",
       " (2, 256),\n",
       " (2, 257),\n",
       " (2, 260),\n",
       " (2, 261),\n",
       " (2, 265),\n",
       " (2, 282),\n",
       " (2, 309),\n",
       " (2, 343),\n",
       " (2, 344),\n",
       " (2, 348),\n",
       " (2, 363),\n",
       " (2, 385),\n",
       " (2, 396),\n",
       " (2, 400),\n",
       " (2, 427),\n",
       " (2, 447),\n",
       " (2, 450),\n",
       " (2, 497),\n",
       " (2, 504),\n",
       " (2, 562),\n",
       " (2, 606),\n",
       " (2, 611),\n",
       " (2, 622),\n",
       " (2, 624),\n",
       " (2, 635),\n",
       " (2, 650),\n",
       " (2, 679),\n",
       " (2, 696),\n",
       " (2, 700),\n",
       " (2, 702),\n",
       " (2, 735),\n",
       " (2, 736),\n",
       " (2, 752),\n",
       " (2, 755),\n",
       " (2, 790),\n",
       " (2, 793),\n",
       " (2, 795),\n",
       " (2, 800),\n",
       " (2, 829),\n",
       " (2, 836),\n",
       " (2, 860),\n",
       " (2, 879),\n",
       " (2, 908),\n",
       " (2, 920),\n",
       " (2, 922),\n",
       " (2, 999),\n",
       " (2, 1001),\n",
       " (2, 1023),\n",
       " (2, 1032),\n",
       " (2, 1033),\n",
       " (2, 1041),\n",
       " (2, 1042),\n",
       " (2, 1048),\n",
       " (2, 1064),\n",
       " (2, 1083),\n",
       " (2, 1087),\n",
       " (2, 1091),\n",
       " (2, 1114),\n",
       " (2, 1116),\n",
       " (2, 1126),\n",
       " (2, 1127),\n",
       " (2, 1130),\n",
       " (2, 1137),\n",
       " (2, 1164),\n",
       " (2, 1172),\n",
       " (2, 1184),\n",
       " (2, 1193),\n",
       " (2, 1200),\n",
       " (2, 1236),\n",
       " (2, 1257),\n",
       " (2, 1264),\n",
       " (2, 1288),\n",
       " (2, 1294),\n",
       " (2, 1319),\n",
       " (2, 1337),\n",
       " (2, 1346),\n",
       " (2, 1351),\n",
       " (2, 1353),\n",
       " (2, 1355),\n",
       " (2, 1370),\n",
       " (2, 1376),\n",
       " (2, 1393),\n",
       " (2, 1479),\n",
       " (2, 1493),\n",
       " (2, 1498),\n",
       " (2, 1505),\n",
       " (2, 1518),\n",
       " (2, 1556),\n",
       " (2, 1561),\n",
       " (2, 1563),\n",
       " (2, 1584),\n",
       " (2, 1588),\n",
       " (2, 1614),\n",
       " (2, 1621),\n",
       " (2, 1654),\n",
       " (2, 1692),\n",
       " (2, 1698),\n",
       " (2, 1705),\n",
       " (2, 1733),\n",
       " (2, 1738),\n",
       " (2, 1803),\n",
       " (2, 1816),\n",
       " (2, 1829),\n",
       " (2, 1849),\n",
       " (2, 1877),\n",
       " (2, 1920),\n",
       " (2, 1933),\n",
       " ...]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into a train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of original ratings. (# of row, # of col): (1000, 10000)\n",
      "the shape of valid ratings. (# of row, # of col): (1000, 10000)\n",
      "Total number of nonzero elements in origial data:1176952\n",
      "Total number of nonzero elements in train data:1068598\n",
      "Total number of nonzero elements in test data:108354\n"
     ]
    }
   ],
   "source": [
    "valid_ratings, train, test = split_data(ratings, p_test=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding parameters for SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SGD_helpers import init_MF, matrix_factorization_SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to find the values of the step size $\\gamma$ first for a fixed value of the 3 other parameters and then compute a grid search to find the best parameters for the regularizers $\\lambda_{user}$, $\\lambda_{item}$ (both between 0 and 1) and the number of features $K$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learn the matrix factorization using SGD with K = 50, lambda_i = 0.01, lambda_u = 0.01, num_epochs = 20\n",
      "iter: 0, RMSE on training set: 4.010824468379098.\n",
      "iter: 5, RMSE on training set: 4.009810800453943.\n",
      "iter: 10, RMSE on training set: 4.009387429041975.\n",
      "iter: 15, RMSE on training set: 4.009214472454605.\n",
      "iter: 19, RMSE on training set: 4.009153914857021.\n",
      "RMSE on test data: 4.013052009085576.\n",
      "Learn the matrix factorization using SGD with K = 50, lambda_i = 0.01, lambda_u = 0.01, num_epochs = 20\n",
      "iter: 0, RMSE on training set: 4.007592440513288.\n",
      "iter: 5, RMSE on training set: 3.989674827963399.\n",
      "iter: 10, RMSE on training set: 3.9767103102659362.\n",
      "iter: 15, RMSE on training set: 3.9699985436600844.\n",
      "iter: 19, RMSE on training set: 3.9674201344576936.\n",
      "RMSE on test data: 3.971264399836704.\n",
      "Learn the matrix factorization using SGD with K = 50, lambda_i = 0.01, lambda_u = 0.01, num_epochs = 20\n",
      "iter: 0, RMSE on training set: 3.837643355350549.\n",
      "iter: 5, RMSE on training set: 1.1710717132071373.\n",
      "iter: 10, RMSE on training set: 1.0682240095802222.\n",
      "iter: 15, RMSE on training set: 1.0487585995054205.\n",
      "iter: 19, RMSE on training set: 1.0434997026069965.\n",
      "RMSE on test data: 1.0518910603828515.\n",
      "Learn the matrix factorization using SGD with K = 50, lambda_i = 0.01, lambda_u = 0.01, num_epochs = 20\n",
      "iter: 0, RMSE on training set: 1.0209030797944731.\n",
      "iter: 5, RMSE on training set: 0.9951074477987697.\n",
      "iter: 10, RMSE on training set: 0.9909605521450483.\n",
      "iter: 15, RMSE on training set: 0.9900151141574566.\n",
      "iter: 19, RMSE on training set: 0.9898568527757446.\n",
      "RMSE on test data: 0.9994955355511117.\n",
      "Learn the matrix factorization using SGD with K = 50, lambda_i = 0.01, lambda_u = 0.01, num_epochs = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luke/Documents/Projects/ML/project2/MRS/src/SGD_helpers.py:57: RuntimeWarning: overflow encountered in multiply\n",
      "  \n",
      "/Users/luke/Documents/Projects/ML/project2/MRS/src/SGD_helpers.py:58: RuntimeWarning: overflow encountered in multiply\n",
      "  rmse = compute_error(train, user_features, item_features, nz_train)\n",
      "/Users/luke/Documents/Projects/ML/project2/MRS/src/SGD_helpers.py:58: RuntimeWarning: invalid value encountered in subtract\n",
      "  rmse = compute_error(train, user_features, item_features, nz_train)\n",
      "/Users/luke/Documents/Projects/ML/project2/MRS/src/SGD_helpers.py:57: RuntimeWarning: invalid value encountered in add\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0, RMSE on training set: nan.\n",
      "iter: 5, RMSE on training set: nan.\n",
      "iter: 10, RMSE on training set: nan.\n",
      "iter: 15, RMSE on training set: nan.\n",
      "iter: 19, RMSE on training set: nan.\n",
      "RMSE on test data: nan.\n",
      "Learn the matrix factorization using SGD with K = 50, lambda_i = 0.01, lambda_u = 0.01, num_epochs = 20\n",
      "iter: 0, RMSE on training set: nan.\n",
      "iter: 5, RMSE on training set: nan.\n",
      "iter: 10, RMSE on training set: nan.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e13e9f9db273>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0muser_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_MF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Compute SGD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix_factorization_SGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_user\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_item\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Projects/ML/project2/MRS/src/SGD_helpers.py\u001b[0m in \u001b[0;36mmatrix_factorization_SGD\u001b[0;34m(train, test, gamma, num_features, lambda_user, lambda_item, num_epochs, user_feat, item_feat, include_test)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0muser_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mitem_info\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlambda_user\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0muser_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnz_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iter: {}, RMSE on training set: {}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Finding gamma:\n",
    "gammas = np.logspace(-5,-1,5)\n",
    "K = 50\n",
    "lambda_user = 0.01\n",
    "lambda_item = 0.01\n",
    "num_epochs = 20\n",
    "errors = []\n",
    "\n",
    "for gamma in gammas:\n",
    "    # Initialize features matrix\n",
    "    user_init, item_init = init_MF(train, K)\n",
    "    # Compute SGD\n",
    "    _, _, rmse = matrix_factorization_SGD(train, test, gamma, K, lambda_user, lambda_item, num_epochs, user_init, item_init)\n",
    "    errors.append(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After many computations (not only on logspace) for same parameters for K and the 2 lambdas, we found that $\\gamma = 0.025$ is the best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As showed in the following grid, we see that the minimal loss is obtained for parameters $\\lambda_{user} = 0.1$ and $\\lambda_{item} = 0.01$ and number of features $K = 20$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1c788fc03c8>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj4AAAHVCAYAAADxWfFwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQseZw0rBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c79195b588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid = np.matrix([[1.1, 1.0481, 1.007, 1.007],[1.0502, 1.0029, 0.9817, 1.0188],[1.0108, 0.9841, 1.0243, 1.0465],[0.994,0.98577,1.02704,1.0481]])\n",
    "fig, ax = plt.subplots(figsize=(15, 7.5))\n",
    "#cmap = sns.light_palette((260, 75, 60), input=\"husl\", reverse = True)\n",
    "sns.heatmap(grid, ax = ax, square = True, annot = True, linewidth = 0.5, fmt='g')\n",
    "lambdas_is = [1.0, 0.1, 0.01, 0.001]\n",
    "lambdas_us = [1.0, 0.1, 0.01, 0.001]\n",
    "ax.set_xticklabels(lambdas_is)\n",
    "ax.set_yticklabels(lambdas_us)\n",
    "ax.set_xlabel(\"Lambda item\")\n",
    "ax.set_ylabel(\"Lambda user\")\n",
    "plt.title(\"Grid Search for minimal RMSE depending on regularizers lambda user and lambda item\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the SGD with the best parameters we found on the whole ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learn the matrix factorization using SGD with K = 50, gamma = 0.025, lambda_i = 0.01, lambda_u = 0.1, num_epochs = 50\n",
      "iter: 0, RMSE on training set: 1.0496954619678236.\n",
      "iter: 5, RMSE on training set: 0.9983686241195876.\n",
      "iter: 10, RMSE on training set: 0.9524652654562149.\n",
      "iter: 15, RMSE on training set: 0.9302734455252297.\n",
      "iter: 20, RMSE on training set: 0.9215310043111165.\n",
      "iter: 25, RMSE on training set: 0.9181243339190256.\n",
      "iter: 30, RMSE on training set: 0.916771667704421.\n",
      "iter: 35, RMSE on training set: 0.9162301837893795.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-1cc632e84fbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0muser_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_MF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m item_feats_SGD, user_feats_SGD, rmse = matrix_factorization_SGD(ratings, test, best_gamma, K, best_lambda_u, best_lambda_i, num_epochs,\n\u001b[0;32m----> 9\u001b[0;31m                                                                     user_init, item_init, include_test = True)\n\u001b[0m",
      "\u001b[0;32m~/Documents/Projects/ML/project2/MRS/src/SGD_helpers.py\u001b[0m in \u001b[0;36mmatrix_factorization_SGD\u001b[0;34m(train, test, gamma, num_features, lambda_user, lambda_item, num_epochs, user_feat, item_feat, include_test)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0muser_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mitem_info\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlambda_user\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0muser_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnz_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iter: {}, RMSE on training set: {}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Projects/ML/project2/MRS/src/SGD_helpers.py\u001b[0m in \u001b[0;36mcompute_error\u001b[0;34m(data, user_features, item_features, nz)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnz\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mitem_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0muser_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mmse\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0muser_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmse\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_gamma = 0.025\n",
    "best_lambda_u = 0.1\n",
    "best_lambda_i = 0.01\n",
    "K = 50\n",
    "num_epochs = 50\n",
    "\n",
    "user_init, item_init = init_MF(ratings, K)\n",
    "item_feats_SGD, user_feats_SGD, rmse = matrix_factorization_SGD(ratings, test, best_gamma, K, best_lambda_u, best_lambda_i, num_epochs,\n",
    "                                                                    user_init, item_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempt_dir = '../tempt/'\n",
    "with open(tempt_dir + 'item_feats_SGD.pk','wb') as f:\n",
    "    pickle.dump(item_feats_SGD, f)\n",
    "with open(tempt_dir + 'user_feats_SGD.pk','wb') as f:\n",
    "    pickle.dump(user_feats_SGD, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempt_dir = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tempt_dir + 'user_feats_SGD.pk','rb') as f:\n",
    "    user_feats_SGD = pickle.load(f)\n",
    "with open(tempt_dir + 'item_feats_SGD.pk','rb') as f:\n",
    "    item_feats_SGD = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of predictions (user x items): (1000, 10000)\n"
     ]
    }
   ],
   "source": [
    "predictions = np.dot(item_feats_SGD.T, user_feats_SGD)\n",
    "print(\"Shape of predictions (user x items): {}\".format(np.shape(predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bias_helpers import computeBiasMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of having $p_{u, i} = \\mathbf{w}_i\\mathbf{z^{T}}_u$ we would add bias on the user and item by having the following:\n",
    "$$p_{u, i} = \\mu + b_{u} + b_{i} + \\mathbf{w}_i\\mathbf{z^{T}}_u$$\n",
    "\n",
    "where $\\mu$ is the average of all ratings, $b_{u}$ and $b_{i}$ are the observed deviations of user u and item i respectively from the average (the biases).\n",
    "\n",
    "Thus we now want to find the best $\\mathbf{W}$ and $\\mathbf{Z}$ that minimizes the loss:\n",
    "\n",
    "$$min_{W,Z} \\sum_{(u, i) \\in \\Omega} (r_{u,i} - \\mu - b_{u} - b_{i} - \\mathbf{W_{u}} \\mathbf{Z^{T}_{i}}) + \\lambda_{item} (||W||_{F}^{2} + b_{i}^{2}) + \\lambda_{user} (||Z||_{F}^{2} + b_{u}^{2}) $$\n",
    "\n",
    "And we need to compute the gradient of this loss. It is the same as before except we can convert our rating matrix to a biased rating matrix with ratings $r'_{u, i} = r_{u, i} - \\mu - b_{u} - b_{i}$ and compute our SGD on this biased matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luke/Documents/Projects/ML/project2/MRS/src/bias_helpers.py:27: RuntimeWarning: invalid value encountered in true_divide\n",
      "  mean_users = [mean_users[0, i] for i in range(num_users)]/nz_users\n",
      "/Users/luke/Documents/Projects/ML/project2/MRS/src/bias_helpers.py:29: RuntimeWarning: invalid value encountered in true_divide\n",
      "  mean_items = [mean_items[i, 0] for i in range(num_items)]/nz_items\n"
     ]
    }
   ],
   "source": [
    "bias_train, mean, bias_u_train, bias_i_train = computeBiasMatrix(train) #ratings for final submissions\n",
    "bias_test, _, _, _ = computeBiasMatrix(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute grid search with best parameters (here just with K = 20 features):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 20, lambda_u = 1.0, lambda_i = 1.0\n",
      "Learn the matrix factorization using SGD with K = 20, lambda_i = 1.0, lambda_u = 1.0, num_epochs = 20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-a05c54c5c0e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"K = {}, lambda_u = {}, lambda_i = {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         item_feats, user_feats, rmse = matrix_factorization_SGD(bias_train, bias_test, gamma, K, lambda_u,\n\u001b[0;32m---> 19\u001b[0;31m                                                                 lambda_i, num_epochs, user_init, item_init)\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;31m### For warm start, we keep the user_features and item_features that gave us the minimal rmse previously computed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrmse\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmin_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Projects/ML/project2/MRS_test/src/SGD_helpers.py\u001b[0m in \u001b[0;36mmatrix_factorization_SGD\u001b[0;34m(train, test, gamma, num_features, lambda_user, lambda_item, num_epochs, user_feat, item_feat, include_test)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0muser_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;31m# calculate the gradient and update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mitem_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0muser_info\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlambda_item\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mitem_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0muser_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mitem_info\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlambda_user\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0muser_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Grid Search:\n",
    "grid = np.zeros((4, 4)) ### np.zeros((4, 4, 4))\n",
    "gamma = 0.025 # best gamma we found above\n",
    "num_epochs = 20\n",
    "lambdas_user = np.logspace(-3,0,4)[::-1] #From max to min\n",
    "lambdas_item = np.logspace(-3,0,4)[::-1]\n",
    "K = 20\n",
    "\n",
    "min_loss = 100000\n",
    "best_user_feats = []\n",
    "best_item_feats = []\n",
    "\n",
    "### Warm start: directly start computation from previously computed item_features and user_features and not random initialization\n",
    "user_init, item_init = init_MF(bias_train, K)\n",
    "for x,lambda_u in enumerate(lambdas_user):\n",
    "    for y,lambda_i in enumerate(lambdas_item):\n",
    "        print(\"K = {}, lambda_u = {}, lambda_i = {}\".format(int(K), lambda_u, lambda_i))\n",
    "        item_feats, user_feats, rmse = matrix_factorization_SGD(bias_train, bias_test, gamma, K, lambda_i,\n",
    "                                                                 lambda_u, num_epochs, user_init, item_init)\n",
    "        ### For warm start, we keep the user_features and item_features that gave us the minimal rmse previously computed\n",
    "        if rmse < min_loss:\n",
    "            print(\"New best\")\n",
    "            min_loss = rmse\n",
    "            user_init = user_feats\n",
    "            item_init = item_feats\n",
    "            best_user_feats = np.copy(user_feats)\n",
    "            best_item_feats = np.copy(item_feats)\n",
    "        grid[x, y] = rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute SGD with the best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learn the matrix factorization using SGD with K = 20, gamma = 0.025, lambda_u = 0.1, lambda_i = 0.001,  num_epochs = 20\n",
      "iter: 0, RMSE on training set: 0.9943391524012675.\n",
      "iter: 5, RMSE on training set: 0.9599108135455338.\n",
      "iter: 10, RMSE on training set: 0.9136724640216513.\n",
      "iter: 15, RMSE on training set: 0.8949050745211748.\n",
      "iter: 19, RMSE on training set: 0.8892296133254736.\n"
     ]
    }
   ],
   "source": [
    "# define parameters\n",
    "gamma = 0.025\n",
    "K = 20\n",
    "lambda_user = 0.1 \n",
    "lambda_item = 0.001\n",
    "num_epochs = 20\n",
    "user_init, item_init = init_MF(bias_train, K)\n",
    "\n",
    "item_featuresSGD, user_featuresSGD, rmse = matrix_factorization_SGD(bias_train, bias_test, gamma, K, lambda_user, lambda_item, num_epochs, user_init, item_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempt_dir = '../tempt/'\n",
    "with open(tempt_dir + 'item_featuresSGD.pk','wb') as f:\n",
    "    pickle.dump(item_featuresSGD, f)\n",
    "with open(tempt_dir + 'user_featuresSGD.pk','wb') as f:\n",
    "    pickle.dump(user_featuresSGD, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "tempt_dir = './'\n",
    "with open(tempt_dir + 'user_features_bias.pk','rb') as f:\n",
    "    user_featuresSGD = pickle.load(f)\n",
    "    \n",
    "with open(tempt_dir + 'item_features_bias.pk','rb') as f:\n",
    "    item_featuresSGD = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of predictions (user x items): (1000, 10000)\n"
     ]
    }
   ],
   "source": [
    "# Compute predictions matrix from the biases, item and user features computed with SGD\n",
    "predictions = predictionsWithBias(item_featuresSGD, user_featuresSGD, bias_u_train, bias_i_train, mean)\n",
    "print(\"Shape of predictions (user x items): {}\".format(np.shape(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 37\n",
      "3.9174388550028096\n"
     ]
    }
   ],
   "source": [
    "### Checking if results appear the same in the final excel file\n",
    "first_user, first_item = sample_ids[0][0],sample_ids[0][1]\n",
    "print(first_item, first_user)\n",
    "print(predictions[first_user - 1, first_item - 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to set the ratings above 5.0 to 5.0 and those below 1.0 to 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum prediction: 1.0, Maximum prediction: 5.0\n"
     ]
    }
   ],
   "source": [
    "predictions[ np.where( predictions > 5.0 ) ] = 5.0\n",
    "predictions[ np.where(predictions < 1.0)] = 1.0\n",
    "print(\"Minimum prediction: {}, Maximum prediction: {}\".format(np.min(predictions), np.max(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of predictions (user x items): (1000, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of predictions (user x items): {}\".format(np.shape(predictions)))\n",
    "wanted_preds = getWantedPredictions(predictions.T, sample_ids)\n",
    "create_csv_submission(sample_ids, np.round(wanted_preds), sub_dir + \"bias_FULL_best_param_50epochs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../submit/'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
