{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "# import scipy\n",
    "# import scipy.io\n",
    "# import scipy.sparse as sp\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_dir = '../data/'\n",
    "sub_dir = '../submit/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "Note that `ratings` is a sparse matrix that in the shape of (num_items, num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 1000, number of users: 10000\n",
      "number of items: 1000, number of users: 10000\n",
      "(1000, 10000)\n"
     ]
    }
   ],
   "source": [
    "from pre_post_process import *\n",
    "\n",
    "_, ratings = load_data(dat_dir + \"data_train.csv\")\n",
    "sample_ids, _ = load_data(dat_dir + \"sample_submission.csv\")\n",
    "print(np.shape(ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ratings = np.sum(ratings, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_item, nb_user = ratings.shape\n",
    "non_zero = ratings.nonzero()\n",
    "non_zero = list(zip(non_zero[0], non_zero[1]))\n",
    "\n",
    "# mu is overall mean\n",
    "mu = np.sum(ratings)/len(non_zero)\n",
    "\n",
    "ratings_per_user = np.zeros((nb_user), dtype=int)\n",
    "ratings_per_item = np.zeros((nb_item), dtype=int)\n",
    "\n",
    "# Compute number of non zero ratings by user and item\n",
    "for item, user in non_zero:\n",
    "    ratings_per_user[user] += 1\n",
    "    ratings_per_item[item] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_avg = np.array(np.sum(ratings, axis = 0)).squeeze()\n",
    "item_avg = np.array(np.sum(ratings, axis = 1)).squeeze()\n",
    "user_avg /= ratings_per_user\n",
    "item_avg /= ratings_per_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.sum(ratings)/len(non_zero)\n",
    "bias_user = user_avg - np.ones(nb_user) * mu\n",
    "bias_item = item_avg - np.ones(nb_item) * mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2515491.5349982167"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(user_avg * nb_user - np.ones(nb_user) * mu *nb_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[3.37941176],\n",
       "        [3.50094162],\n",
       "        [3.48358586],\n",
       "        [3.93647282],\n",
       "        [3.55913113],\n",
       "        [4.68276973],\n",
       "        [3.44661922],\n",
       "        [3.87749706],\n",
       "        [2.90196078],\n",
       "        [3.6460717 ],\n",
       "        [3.27668659],\n",
       "        [3.2       ],\n",
       "        [3.47954545],\n",
       "        [4.4244857 ],\n",
       "        [3.14275668],\n",
       "        [3.43146603],\n",
       "        [2.65807068],\n",
       "        [2.40201729],\n",
       "        [3.49333333],\n",
       "        [2.91961415],\n",
       "        [3.55738576],\n",
       "        [3.0980826 ],\n",
       "        [3.34537572],\n",
       "        [3.71028037],\n",
       "        [3.54098361],\n",
       "        [4.12449637],\n",
       "        [3.74821173],\n",
       "        [3.65977444],\n",
       "        [3.55257271],\n",
       "        [3.85899094],\n",
       "        [3.18181818],\n",
       "        [3.44074437],\n",
       "        [3.40510638],\n",
       "        [3.42634855],\n",
       "        [3.09515419],\n",
       "        [3.43018868],\n",
       "        [3.72618094],\n",
       "        [3.05277778],\n",
       "        [3.02994012],\n",
       "        [3.74283439],\n",
       "        [2.83333333],\n",
       "        [3.50403691],\n",
       "        [3.5837766 ],\n",
       "        [3.57862781],\n",
       "        [4.04652937],\n",
       "        [4.44621888],\n",
       "        [3.44354839],\n",
       "        [3.77649326],\n",
       "        [2.55855856],\n",
       "        [2.98664122],\n",
       "        [3.90618412],\n",
       "        [3.66129032],\n",
       "        [3.77406282],\n",
       "        [3.18888889],\n",
       "        [3.77170139],\n",
       "        [2.69753086],\n",
       "        [3.3688029 ],\n",
       "        [3.16666667],\n",
       "        [4.01806756],\n",
       "        [4.56155349],\n",
       "        [3.88483374],\n",
       "        [3.47847682],\n",
       "        [3.56142132],\n",
       "        [3.37959866],\n",
       "        [3.1086351 ],\n",
       "        [3.68593449],\n",
       "        [3.52216749],\n",
       "        [3.50505051],\n",
       "        [3.83134796],\n",
       "        [3.19957082],\n",
       "        [3.33873582],\n",
       "        [3.67172012],\n",
       "        [3.28676471],\n",
       "        [3.2237037 ],\n",
       "        [2.77224199],\n",
       "        [4.23130938],\n",
       "        [3.76877133],\n",
       "        [3.81932773],\n",
       "        [3.65371809],\n",
       "        [3.41791045],\n",
       "        [3.48833034],\n",
       "        [3.48930481],\n",
       "        [3.49221184],\n",
       "        [4.17531798],\n",
       "        [3.2755102 ],\n",
       "        [3.81422165],\n",
       "        [3.30434783],\n",
       "        [3.37579618],\n",
       "        [4.12574431],\n",
       "        [3.11938776],\n",
       "        [3.36679537],\n",
       "        [3.31031543],\n",
       "        [3.75224857],\n",
       "        [3.88101161],\n",
       "        [4.035988  ],\n",
       "        [2.62574257],\n",
       "        [2.63968668],\n",
       "        [3.20400729],\n",
       "        [3.8030914 ],\n",
       "        [3.38814016],\n",
       "        [3.66850394],\n",
       "        [4.18722901],\n",
       "        [3.09657948],\n",
       "        [2.68443497],\n",
       "        [3.2020649 ],\n",
       "        [3.91044776],\n",
       "        [3.33792049],\n",
       "        [3.17234848],\n",
       "        [2.88888889],\n",
       "        [3.40060241],\n",
       "        [3.6344086 ],\n",
       "        [3.95768374],\n",
       "        [3.09469154],\n",
       "        [2.7       ],\n",
       "        [2.48546512],\n",
       "        [3.41077441],\n",
       "        [3.72723005],\n",
       "        [4.32687166],\n",
       "        [3.06692913],\n",
       "        [3.54288499],\n",
       "        [3.50698603],\n",
       "        [3.28067885],\n",
       "        [3.053407  ],\n",
       "        [3.26356589],\n",
       "        [2.97055215],\n",
       "        [3.73366419],\n",
       "        [3.44977679],\n",
       "        [3.60833333],\n",
       "        [2.97854077],\n",
       "        [3.32758621],\n",
       "        [4.31204188],\n",
       "        [3.58185053],\n",
       "        [3.16193182],\n",
       "        [4.18327491],\n",
       "        [2.43271222],\n",
       "        [3.422     ],\n",
       "        [3.54245283],\n",
       "        [3.24148004],\n",
       "        [3.9697591 ],\n",
       "        [3.01079137],\n",
       "        [3.19287374],\n",
       "        [3.36650485],\n",
       "        [4.33800774],\n",
       "        [3.3141994 ],\n",
       "        [2.98014888],\n",
       "        [3.46716981],\n",
       "        [2.82945736],\n",
       "        [4.49694239],\n",
       "        [3.09638554],\n",
       "        [3.75609756],\n",
       "        [3.24242424],\n",
       "        [3.3960396 ],\n",
       "        [3.325     ],\n",
       "        [3.49142857],\n",
       "        [3.60244989],\n",
       "        [4.66821238],\n",
       "        [4.04056437],\n",
       "        [3.3369906 ],\n",
       "        [3.31578947],\n",
       "        [2.93530997],\n",
       "        [4.23924647],\n",
       "        [3.61538462],\n",
       "        [3.25587467],\n",
       "        [3.65350318],\n",
       "        [3.67752443],\n",
       "        [2.83116883],\n",
       "        [3.8220339 ],\n",
       "        [3.65205843],\n",
       "        [3.98353096],\n",
       "        [3.78617249],\n",
       "        [4.33953998],\n",
       "        [3.02145215],\n",
       "        [3.6308266 ],\n",
       "        [3.79676441],\n",
       "        [3.05949657],\n",
       "        [4.34363814],\n",
       "        [3.88570039],\n",
       "        [4.49346405],\n",
       "        [3.50338462],\n",
       "        [3.0842246 ],\n",
       "        [3.59303483],\n",
       "        [3.26462049],\n",
       "        [3.58205805],\n",
       "        [3.6526238 ],\n",
       "        [3.05988024],\n",
       "        [3.61938062],\n",
       "        [3.40680713],\n",
       "        [4.13263322],\n",
       "        [3.60426929],\n",
       "        [3.16635161],\n",
       "        [4.48688932],\n",
       "        [3.17045455],\n",
       "        [4.10101772],\n",
       "        [3.19521912],\n",
       "        [3.21551724],\n",
       "        [3.15294118],\n",
       "        [3.70869277],\n",
       "        [4.08029197],\n",
       "        [3.24056604],\n",
       "        [3.82819957],\n",
       "        [2.83333333],\n",
       "        [3.28051948],\n",
       "        [4.11968811],\n",
       "        [2.75321888],\n",
       "        [3.08884688],\n",
       "        [3.97449909],\n",
       "        [3.13682678],\n",
       "        [3.64128596],\n",
       "        [3.24210526],\n",
       "        [3.67076167],\n",
       "        [3.6458498 ],\n",
       "        [3.50414594],\n",
       "        [3.87963409],\n",
       "        [4.0305368 ],\n",
       "        [4.00156006],\n",
       "        [4.24216792],\n",
       "        [3.76844784],\n",
       "        [4.12236287],\n",
       "        [3.92904953],\n",
       "        [3.68699187],\n",
       "        [3.50395778],\n",
       "        [3.80914513],\n",
       "        [3.52844311],\n",
       "        [3.56428571],\n",
       "        [3.33084112],\n",
       "        [3.29090909],\n",
       "        [3.59951456],\n",
       "        [3.28095238],\n",
       "        [3.59285714],\n",
       "        [3.98294401],\n",
       "        [3.02689487],\n",
       "        [3.3974359 ],\n",
       "        [3.79863014],\n",
       "        [3.37985136],\n",
       "        [3.8630137 ],\n",
       "        [3.96549521],\n",
       "        [3.41660261],\n",
       "        [3.22496148],\n",
       "        [3.60664336],\n",
       "        [3.24679761],\n",
       "        [3.75641026],\n",
       "        [3.90215924],\n",
       "        [3.02222222],\n",
       "        [3.69820555],\n",
       "        [4.20975431],\n",
       "        [3.85914595],\n",
       "        [3.90498442],\n",
       "        [2.73258706],\n",
       "        [4.0184244 ],\n",
       "        [3.65239646],\n",
       "        [4.358686  ],\n",
       "        [3.25173611],\n",
       "        [3.81975737],\n",
       "        [3.784375  ],\n",
       "        [3.06896552],\n",
       "        [4.72625426],\n",
       "        [4.50040839],\n",
       "        [4.19621003],\n",
       "        [3.37992495],\n",
       "        [3.56302521],\n",
       "        [3.06625259],\n",
       "        [3.77441406],\n",
       "        [3.02491694],\n",
       "        [4.0706278 ],\n",
       "        [3.3962963 ],\n",
       "        [3.75303903],\n",
       "        [3.49187935],\n",
       "        [3.50455927],\n",
       "        [3.86458333],\n",
       "        [3.36862745],\n",
       "        [3.77340332],\n",
       "        [3.16297787],\n",
       "        [3.32492114],\n",
       "        [3.27822121],\n",
       "        [3.31620553],\n",
       "        [3.12087912],\n",
       "        [2.91896552],\n",
       "        [2.72187777],\n",
       "        [3.04668305],\n",
       "        [3.16896552],\n",
       "        [3.64242424],\n",
       "        [3.67391304],\n",
       "        [3.6663744 ],\n",
       "        [2.89937107],\n",
       "        [3.95367412],\n",
       "        [3.05501618],\n",
       "        [3.46182266],\n",
       "        [3.21981004],\n",
       "        [3.35768262],\n",
       "        [3.38589212],\n",
       "        [3.59095106],\n",
       "        [2.57575758],\n",
       "        [2.76734104],\n",
       "        [3.30924855],\n",
       "        [4.34506837],\n",
       "        [4.20822838],\n",
       "        [4.22245431],\n",
       "        [4.08883953],\n",
       "        [3.60544218],\n",
       "        [3.96481813],\n",
       "        [4.26421011],\n",
       "        [4.35344828],\n",
       "        [3.91470258],\n",
       "        [4.05159166],\n",
       "        [3.78020566],\n",
       "        [4.41131204],\n",
       "        [4.06607495],\n",
       "        [4.20809524],\n",
       "        [4.01888668],\n",
       "        [4.55795739],\n",
       "        [4.33669549],\n",
       "        [4.05341246],\n",
       "        [4.04275654],\n",
       "        [4.        ],\n",
       "        [3.4       ],\n",
       "        [3.72116603],\n",
       "        [4.49344125],\n",
       "        [4.20799719],\n",
       "        [3.76545166],\n",
       "        [4.37970192],\n",
       "        [4.39940498],\n",
       "        [4.32719589],\n",
       "        [3.27309237],\n",
       "        [4.21230159],\n",
       "        [3.5140665 ],\n",
       "        [3.9599141 ],\n",
       "        [3.47286822],\n",
       "        [4.27528902],\n",
       "        [3.94269341],\n",
       "        [3.68033776],\n",
       "        [3.96785255],\n",
       "        [3.84352865],\n",
       "        [3.97156783],\n",
       "        [3.81977671],\n",
       "        [4.05989848],\n",
       "        [3.81034483],\n",
       "        [3.97149938],\n",
       "        [3.80195599],\n",
       "        [3.09041096],\n",
       "        [3.84177998],\n",
       "        [3.64593301],\n",
       "        [3.88811189],\n",
       "        [3.91333333],\n",
       "        [3.80143113],\n",
       "        [3.9093199 ],\n",
       "        [3.59821429],\n",
       "        [3.87159533],\n",
       "        [4.15230961],\n",
       "        [3.84038308],\n",
       "        [4.05321429],\n",
       "        [4.1983871 ],\n",
       "        [3.9215587 ],\n",
       "        [3.99530075],\n",
       "        [3.81647059],\n",
       "        [2.86896552],\n",
       "        [3.02727273],\n",
       "        [3.15614618],\n",
       "        [3.79138514],\n",
       "        [3.5638051 ],\n",
       "        [3.8354232 ],\n",
       "        [3.41267606],\n",
       "        [2.72207084],\n",
       "        [4.05250597],\n",
       "        [3.62197802],\n",
       "        [3.86342229],\n",
       "        [3.93441672],\n",
       "        [4.26463474],\n",
       "        [3.53626374],\n",
       "        [3.75494881],\n",
       "        [4.05657895],\n",
       "        [3.85655738],\n",
       "        [3.65298507],\n",
       "        [3.88118812],\n",
       "        [3.5       ],\n",
       "        [3.82901554],\n",
       "        [3.49482402],\n",
       "        [3.64285714],\n",
       "        [3.10714286],\n",
       "        [3.78250702],\n",
       "        [3.43724696],\n",
       "        [3.96612296],\n",
       "        [3.37758112],\n",
       "        [3.36918605],\n",
       "        [3.65394402],\n",
       "        [3.5960199 ],\n",
       "        [3.97983871],\n",
       "        [4.14134276],\n",
       "        [3.58013544],\n",
       "        [3.82425068],\n",
       "        [3.08450704],\n",
       "        [3.63300971],\n",
       "        [4.06699752],\n",
       "        [4.02305476],\n",
       "        [3.19708995],\n",
       "        [3.89213483],\n",
       "        [3.84984026],\n",
       "        [3.51092612],\n",
       "        [3.70809485],\n",
       "        [3.66374781],\n",
       "        [3.65057471],\n",
       "        [3.44162437],\n",
       "        [3.7810559 ],\n",
       "        [3.65422535],\n",
       "        [3.30734967],\n",
       "        [3.60218509],\n",
       "        [3.78428928],\n",
       "        [3.27850163],\n",
       "        [3.21221374],\n",
       "        [3.39449541],\n",
       "        [3.60928652],\n",
       "        [3.30075188],\n",
       "        [4.21474654],\n",
       "        [3.35228677],\n",
       "        [3.17379679],\n",
       "        [3.5010846 ],\n",
       "        [3.86986987],\n",
       "        [3.7260653 ],\n",
       "        [3.47753623],\n",
       "        [3.03531073],\n",
       "        [3.82879147],\n",
       "        [3.88841927],\n",
       "        [3.29566855],\n",
       "        [3.96066863],\n",
       "        [3.22155689],\n",
       "        [3.57588076],\n",
       "        [4.00524246],\n",
       "        [3.77867903],\n",
       "        [3.11515864],\n",
       "        [3.44799054],\n",
       "        [3.71209801],\n",
       "        [3.5245098 ],\n",
       "        [3.86697966],\n",
       "        [4.10400348],\n",
       "        [4.35470668],\n",
       "        [3.05714286],\n",
       "        [3.44239631],\n",
       "        [2.9245283 ],\n",
       "        [3.31125828],\n",
       "        [4.0928743 ],\n",
       "        [3.75576582],\n",
       "        [3.12312312],\n",
       "        [3.37931034],\n",
       "        [3.2037037 ],\n",
       "        [3.4578853 ],\n",
       "        [4.33753296],\n",
       "        [3.78670788],\n",
       "        [3.51541426],\n",
       "        [3.77117385],\n",
       "        [3.63210702],\n",
       "        [3.97484277],\n",
       "        [3.48697917],\n",
       "        [3.37460978],\n",
       "        [3.40146879],\n",
       "        [3.2103929 ],\n",
       "        [3.46699787],\n",
       "        [3.76216216],\n",
       "        [3.94139887],\n",
       "        [4.31944923],\n",
       "        [4.31407117],\n",
       "        [2.87168142],\n",
       "        [3.66428571],\n",
       "        [3.10829817],\n",
       "        [3.22083333],\n",
       "        [3.63858696],\n",
       "        [3.55138122],\n",
       "        [3.70866935],\n",
       "        [3.64586357],\n",
       "        [3.48148148],\n",
       "        [3.74901961],\n",
       "        [3.34736842],\n",
       "        [4.33537051],\n",
       "        [3.64902103],\n",
       "        [3.9079516 ],\n",
       "        [3.79250107],\n",
       "        [3.91033539],\n",
       "        [3.884203  ],\n",
       "        [4.23395103],\n",
       "        [4.24540728],\n",
       "        [3.627829  ],\n",
       "        [3.79746835],\n",
       "        [3.43911917],\n",
       "        [4.00337079],\n",
       "        [3.56122449],\n",
       "        [4.11818182],\n",
       "        [4.07768431],\n",
       "        [3.56819407],\n",
       "        [4.38994446],\n",
       "        [4.11616954],\n",
       "        [3.5143277 ],\n",
       "        [3.75757576],\n",
       "        [3.60596447],\n",
       "        [4.06304438],\n",
       "        [3.89799477],\n",
       "        [4.02791878],\n",
       "        [4.36513242],\n",
       "        [3.91436727],\n",
       "        [3.77005076],\n",
       "        [3.26910569],\n",
       "        [3.963047  ],\n",
       "        [2.95294118],\n",
       "        [3.92238806],\n",
       "        [4.15276753],\n",
       "        [2.49822064],\n",
       "        [3.08018868],\n",
       "        [2.75      ],\n",
       "        [3.21453287],\n",
       "        [2.39552239],\n",
       "        [3.90773229],\n",
       "        [3.92008639],\n",
       "        [3.10875332],\n",
       "        [3.34768212],\n",
       "        [3.388     ],\n",
       "        [3.19117647],\n",
       "        [3.51360544],\n",
       "        [3.62275449],\n",
       "        [3.37878788],\n",
       "        [3.63625731],\n",
       "        [3.74750623],\n",
       "        [3.31288344],\n",
       "        [3.36206897],\n",
       "        [2.82995951],\n",
       "        [3.7834681 ],\n",
       "        [3.73741286],\n",
       "        [2.65378422],\n",
       "        [3.99471099],\n",
       "        [3.03380282],\n",
       "        [3.62737876],\n",
       "        [3.36      ],\n",
       "        [4.12693498],\n",
       "        [4.11714286],\n",
       "        [4.05      ],\n",
       "        [2.62376238],\n",
       "        [3.30248307],\n",
       "        [4.5207617 ],\n",
       "        [3.13761468],\n",
       "        [3.954371  ],\n",
       "        [3.19650655],\n",
       "        [3.61443299],\n",
       "        [3.76847291],\n",
       "        [3.16666667],\n",
       "        [2.72689076],\n",
       "        [3.53625378],\n",
       "        [3.66754967],\n",
       "        [3.79631761],\n",
       "        [3.69647202],\n",
       "        [4.27525058],\n",
       "        [4.04810209],\n",
       "        [3.71871872],\n",
       "        [3.5407332 ],\n",
       "        [3.7355959 ],\n",
       "        [3.70838941],\n",
       "        [3.26766091],\n",
       "        [3.65178033],\n",
       "        [3.74365647],\n",
       "        [2.97321429],\n",
       "        [3.43625192],\n",
       "        [3.40620592],\n",
       "        [3.7800729 ],\n",
       "        [3.73824786],\n",
       "        [3.53859348],\n",
       "        [3.22181818],\n",
       "        [3.24256087],\n",
       "        [3.92307692],\n",
       "        [3.625387  ],\n",
       "        [3.68574109],\n",
       "        [2.27252252],\n",
       "        [3.17672414],\n",
       "        [3.11173184],\n",
       "        [3.91318328],\n",
       "        [4.28108108],\n",
       "        [3.13732155],\n",
       "        [3.14214876],\n",
       "        [4.16194734],\n",
       "        [3.71494253],\n",
       "        [3.87514318],\n",
       "        [3.76056338],\n",
       "        [3.87245971],\n",
       "        [3.5890411 ],\n",
       "        [3.44281525],\n",
       "        [3.57885615],\n",
       "        [3.95618755],\n",
       "        [3.7486911 ],\n",
       "        [3.83560091],\n",
       "        [3.73658872],\n",
       "        [3.36585366],\n",
       "        [3.99765258],\n",
       "        [4.05427408],\n",
       "        [3.49004975],\n",
       "        [3.30141844],\n",
       "        [3.63231198],\n",
       "        [4.5464846 ],\n",
       "        [3.45437956],\n",
       "        [3.62025316],\n",
       "        [4.68203498],\n",
       "        [4.52974277],\n",
       "        [4.69184007],\n",
       "        [4.1730427 ],\n",
       "        [4.46157951],\n",
       "        [4.23184666],\n",
       "        [3.74013158],\n",
       "        [4.28410439],\n",
       "        [4.35426429],\n",
       "        [3.3986014 ],\n",
       "        [4.32324576],\n",
       "        [4.40075219],\n",
       "        [4.33663366],\n",
       "        [4.03248588],\n",
       "        [4.63942094],\n",
       "        [4.03758389],\n",
       "        [4.2959364 ],\n",
       "        [4.44883998],\n",
       "        [4.44305177],\n",
       "        [3.87060998],\n",
       "        [3.21546261],\n",
       "        [4.19400545],\n",
       "        [4.12564407],\n",
       "        [4.31245768],\n",
       "        [4.25252216],\n",
       "        [4.53235908],\n",
       "        [4.26055858],\n",
       "        [4.17655468],\n",
       "        [3.95212766],\n",
       "        [4.34114927],\n",
       "        [3.69172932],\n",
       "        [3.85169029],\n",
       "        [4.23615307],\n",
       "        [3.72131148],\n",
       "        [4.31486239],\n",
       "        [4.07750865],\n",
       "        [3.88284519],\n",
       "        [4.29706927],\n",
       "        [4.40268456],\n",
       "        [4.13043478],\n",
       "        [3.90196078],\n",
       "        [3.9246172 ],\n",
       "        [3.84606205],\n",
       "        [3.39130435],\n",
       "        [4.39407446],\n",
       "        [3.77207063],\n",
       "        [4.21897482],\n",
       "        [3.90280778],\n",
       "        [4.07896104],\n",
       "        [4.1759065 ],\n",
       "        [4.22684564],\n",
       "        [4.32043989],\n",
       "        [4.20322581],\n",
       "        [3.91640706],\n",
       "        [4.28358882],\n",
       "        [3.91366906],\n",
       "        [4.27920561],\n",
       "        [4.06465517],\n",
       "        [3.68060837],\n",
       "        [3.4279476 ],\n",
       "        [4.19904762],\n",
       "        [3.91809181],\n",
       "        [4.31510334],\n",
       "        [4.41040956],\n",
       "        [4.18859365],\n",
       "        [4.04683196],\n",
       "        [4.37916219],\n",
       "        [4.25212465],\n",
       "        [3.96187364],\n",
       "        [4.41318977],\n",
       "        [4.16212711],\n",
       "        [4.23944511],\n",
       "        [3.53066667],\n",
       "        [4.18242123],\n",
       "        [4.53617325],\n",
       "        [3.91430455],\n",
       "        [4.14534884],\n",
       "        [3.85866261],\n",
       "        [3.84330868],\n",
       "        [3.84758551],\n",
       "        [4.1641791 ],\n",
       "        [3.9049505 ],\n",
       "        [4.19317269],\n",
       "        [3.6971831 ],\n",
       "        [3.92403487],\n",
       "        [3.65432836],\n",
       "        [3.95361071],\n",
       "        [4.18714556],\n",
       "        [4.30553328],\n",
       "        [4.        ],\n",
       "        [3.8312541 ],\n",
       "        [4.01082381],\n",
       "        [4.24874856],\n",
       "        [3.86737805],\n",
       "        [3.4665493 ],\n",
       "        [4.41558442],\n",
       "        [3.95336391],\n",
       "        [4.12080925],\n",
       "        [2.72761194],\n",
       "        [3.72484848],\n",
       "        [4.09404234],\n",
       "        [3.86613546],\n",
       "        [3.86666667],\n",
       "        [4.16979866],\n",
       "        [3.91311903],\n",
       "        [3.7326087 ],\n",
       "        [4.02865228],\n",
       "        [4.03655352],\n",
       "        [4.22784343],\n",
       "        [3.79764244],\n",
       "        [3.53752535],\n",
       "        [4.4049679 ],\n",
       "        [4.0040032 ],\n",
       "        [3.32012848],\n",
       "        [3.55769231],\n",
       "        [3.05263158],\n",
       "        [3.46056782],\n",
       "        [2.81034483],\n",
       "        [3.56213018],\n",
       "        [3.75167785],\n",
       "        [3.35616438],\n",
       "        [3.46190476],\n",
       "        [3.88115135],\n",
       "        [3.53459119],\n",
       "        [3.55006617],\n",
       "        [4.1163575 ],\n",
       "        [3.19329897],\n",
       "        [2.32941176],\n",
       "        [3.82172915],\n",
       "        [3.1901566 ],\n",
       "        [3.0462963 ],\n",
       "        [3.15549598],\n",
       "        [3.25513514],\n",
       "        [3.85666105],\n",
       "        [3.05902192],\n",
       "        [3.17975207],\n",
       "        [2.86267606],\n",
       "        [3.93772704],\n",
       "        [3.17558528],\n",
       "        [4.23198198],\n",
       "        [2.70408163],\n",
       "        [3.24210526],\n",
       "        [2.96238938],\n",
       "        [3.64029536],\n",
       "        [3.3419227 ],\n",
       "        [3.39530133],\n",
       "        [3.06860158],\n",
       "        [3.72170106],\n",
       "        [3.82590412],\n",
       "        [3.62566489],\n",
       "        [3.17148362],\n",
       "        [3.66666667],\n",
       "        [4.02942468],\n",
       "        [3.96196868],\n",
       "        [3.74784111],\n",
       "        [3.71246459],\n",
       "        [3.17159091],\n",
       "        [3.33198925],\n",
       "        [3.82877527],\n",
       "        [3.16853933],\n",
       "        [4.07740655],\n",
       "        [3.97782003],\n",
       "        [4.19405594],\n",
       "        [2.68786982],\n",
       "        [3.56097561],\n",
       "        [3.84747706],\n",
       "        [4.13553719],\n",
       "        [3.26008065],\n",
       "        [2.56395349],\n",
       "        [3.80898876],\n",
       "        [3.50753769],\n",
       "        [3.52757949],\n",
       "        [4.0295858 ],\n",
       "        [3.99570815],\n",
       "        [3.80761603],\n",
       "        [4.18313753],\n",
       "        [3.64255519],\n",
       "        [2.98433048],\n",
       "        [4.06851785],\n",
       "        [3.56550665],\n",
       "        [4.03886926],\n",
       "        [3.74208333],\n",
       "        [3.67448276],\n",
       "        [3.58206565],\n",
       "        [3.70808679],\n",
       "        [3.97378004],\n",
       "        [2.7987988 ],\n",
       "        [3.66636114],\n",
       "        [2.79023508],\n",
       "        [3.5918775 ],\n",
       "        [2.74074074],\n",
       "        [4.20694006],\n",
       "        [2.7654185 ],\n",
       "        [3.19913952],\n",
       "        [3.22166247],\n",
       "        [3.41321389],\n",
       "        [3.62979684],\n",
       "        [4.24310552],\n",
       "        [4.23558801],\n",
       "        [3.34749621],\n",
       "        [3.90381206],\n",
       "        [3.24041812],\n",
       "        [3.80941176],\n",
       "        [3.9598678 ],\n",
       "        [3.25274725],\n",
       "        [3.37424058],\n",
       "        [3.61424332],\n",
       "        [3.81884058],\n",
       "        [4.00289296],\n",
       "        [3.61058201],\n",
       "        [3.66143498],\n",
       "        [3.89871152],\n",
       "        [4.10794543],\n",
       "        [3.24349286],\n",
       "        [4.07979226],\n",
       "        [3.86117837],\n",
       "        [3.73169014],\n",
       "        [3.49932157],\n",
       "        [3.59147425],\n",
       "        [3.3630363 ],\n",
       "        [3.49518459],\n",
       "        [3.76186292],\n",
       "        [4.13201727],\n",
       "        [3.67286245],\n",
       "        [3.34536082],\n",
       "        [3.31072555],\n",
       "        [3.3583691 ],\n",
       "        [3.42857143],\n",
       "        [3.359401  ],\n",
       "        [3.54909366],\n",
       "        [3.61584158],\n",
       "        [3.84938942],\n",
       "        [3.38815789],\n",
       "        [3.62380539],\n",
       "        [3.5193133 ],\n",
       "        [2.925     ],\n",
       "        [3.13367609],\n",
       "        [3.45038168],\n",
       "        [3.23355263],\n",
       "        [3.48463902],\n",
       "        [3.57514793],\n",
       "        [3.63247863],\n",
       "        [3.19984974],\n",
       "        [2.98314607],\n",
       "        [3.04863222],\n",
       "        [3.61593554],\n",
       "        [3.54044118],\n",
       "        [3.92      ],\n",
       "        [3.50473186],\n",
       "        [3.62443439],\n",
       "        [3.9602649 ],\n",
       "        [3.31034483],\n",
       "        [3.72540046],\n",
       "        [4.06088174],\n",
       "        [3.62992126],\n",
       "        [3.87295082],\n",
       "        [3.85419532],\n",
       "        [2.91310976],\n",
       "        [3.34924623],\n",
       "        [3.47376917],\n",
       "        [3.6541233 ],\n",
       "        [3.29508197],\n",
       "        [2.95384615],\n",
       "        [3.50607287],\n",
       "        [2.90136054],\n",
       "        [2.86380597],\n",
       "        [3.74358974],\n",
       "        [3.04897959],\n",
       "        [3.3258547 ],\n",
       "        [3.38043478],\n",
       "        [4.05098605],\n",
       "        [3.40756303],\n",
       "        [3.09750567],\n",
       "        [4.01388889],\n",
       "        [3.44186047],\n",
       "        [3.48888889],\n",
       "        [3.48484848],\n",
       "        [3.53052632],\n",
       "        [2.66017316],\n",
       "        [2.94466403],\n",
       "        [3.57698413],\n",
       "        [2.98522167],\n",
       "        [4.31992231],\n",
       "        [3.81889764],\n",
       "        [3.38872832],\n",
       "        [3.34444444],\n",
       "        [3.37229437],\n",
       "        [2.91726619],\n",
       "        [3.58863636],\n",
       "        [3.66743827],\n",
       "        [3.09178744],\n",
       "        [3.15039578],\n",
       "        [3.26996198],\n",
       "        [2.96111111],\n",
       "        [3.7195572 ],\n",
       "        [3.36938202],\n",
       "        [3.79613095],\n",
       "        [2.84771987],\n",
       "        [3.10079051],\n",
       "        [2.02222222],\n",
       "        [3.38880918],\n",
       "        [2.48962656],\n",
       "        [3.49588138],\n",
       "        [2.46265761],\n",
       "        [3.97648515],\n",
       "        [3.44793388],\n",
       "        [3.46712803],\n",
       "        [2.63862928],\n",
       "        [3.4552381 ],\n",
       "        [2.57692308],\n",
       "        [3.9015544 ],\n",
       "        [3.46090535],\n",
       "        [3.4729207 ],\n",
       "        [3.1981982 ],\n",
       "        [3.27480916],\n",
       "        [3.31884058],\n",
       "        [3.37333333],\n",
       "        [3.26501035],\n",
       "        [3.172     ],\n",
       "        [3.11483254],\n",
       "        [3.00259067],\n",
       "        [4.08224076],\n",
       "        [3.52259332],\n",
       "        [3.18      ],\n",
       "        [3.49404762],\n",
       "        [3.61797753],\n",
       "        [3.33112583],\n",
       "        [3.40581442],\n",
       "        [3.54724409],\n",
       "        [2.80099502],\n",
       "        [2.89230769],\n",
       "        [4.15324985],\n",
       "        [3.40206186],\n",
       "        [4.02509653],\n",
       "        [2.21052632],\n",
       "        [3.5       ],\n",
       "        [3.65608466],\n",
       "        [3.51973684],\n",
       "        [3.8033241 ],\n",
       "        [3.64121435],\n",
       "        [3.59656652],\n",
       "        [4.03788749],\n",
       "        [3.12309496],\n",
       "        [3.44110276],\n",
       "        [3.78059072],\n",
       "        [3.32669983],\n",
       "        [3.63884892],\n",
       "        [3.35036496],\n",
       "        [3.36367596],\n",
       "        [3.50123457],\n",
       "        [2.78388278],\n",
       "        [3.70308789],\n",
       "        [2.87878788],\n",
       "        [3.15934066],\n",
       "        [2.87165775],\n",
       "        [2.57471264],\n",
       "        [3.65134907],\n",
       "        [3.77777778],\n",
       "        [3.74719101],\n",
       "        [3.46341463],\n",
       "        [2.28877005],\n",
       "        [2.625     ],\n",
       "        [3.37142857],\n",
       "        [3.34782609],\n",
       "        [3.1130742 ],\n",
       "        [2.35227273],\n",
       "        [2.58009543],\n",
       "        [2.82170543],\n",
       "        [2.90551181],\n",
       "        [2.8253012 ],\n",
       "        [3.33573635],\n",
       "        [2.64912281],\n",
       "        [3.58579882],\n",
       "        [3.53493834],\n",
       "        [3.24561404],\n",
       "        [4.01381215],\n",
       "        [3.45171849],\n",
       "        [3.76791444],\n",
       "        [3.35313002],\n",
       "        [3.7047619 ],\n",
       "        [3.71014493],\n",
       "        [3.70034843],\n",
       "        [3.53125   ],\n",
       "        [3.44692737],\n",
       "        [4.2604913 ],\n",
       "        [3.80931744],\n",
       "        [3.94129763],\n",
       "        [4.04716981],\n",
       "        [4.12720848],\n",
       "        [3.51987448],\n",
       "        [3.45976253],\n",
       "        [3.37292359],\n",
       "        [3.16120219],\n",
       "        [3.33831283],\n",
       "        [2.91646778],\n",
       "        [3.22117476],\n",
       "        [2.91333333],\n",
       "        [2.91037736],\n",
       "        [3.62021858],\n",
       "        [2.77755102],\n",
       "        [3.28176796],\n",
       "        [3.75250109],\n",
       "        [3.34768481],\n",
       "        [3.43537415],\n",
       "        [3.23940678],\n",
       "        [3.3539823 ],\n",
       "        [3.68230563]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_avg / ratings_per_item.reshape(item_avg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into a train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of original ratings. (# of row, # of col): (1000, 10000)\n",
      "the shape of valid ratings. (# of row, # of col): (1000, 10000)\n",
      "Total number of nonzero elements in origial data:1176952\n",
      "Total number of nonzero elements in train data:1068598\n",
      "Total number of nonzero elements in test data:108354\n"
     ]
    }
   ],
   "source": [
    "valid_ratings, train, test = split_data(ratings, p_test=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding parameters for SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SGD_helpers import init_MF, matrix_factorization_SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to find the values of the step size $\\gamma$ first for a fixed value of the 3 other parameters and then compute a grid search to find the best parameters for the regularizers $\\lambda_{user}$, $\\lambda_{item}$ (both between 0 and 1) and the number of features $K$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learn the matrix factorization using SGD with K = 50, lambda_i = 0.01, lambda_u = 0.01, num_epochs = 20\n",
      "iter: 0, RMSE on training set: 4.010824468379098.\n",
      "iter: 5, RMSE on training set: 4.009810800453943.\n",
      "iter: 10, RMSE on training set: 4.009387429041975.\n",
      "iter: 15, RMSE on training set: 4.009214472454605.\n",
      "iter: 19, RMSE on training set: 4.009153914857021.\n",
      "RMSE on test data: 4.013052009085576.\n",
      "Learn the matrix factorization using SGD with K = 50, lambda_i = 0.01, lambda_u = 0.01, num_epochs = 20\n",
      "iter: 0, RMSE on training set: 4.007592440513288.\n",
      "iter: 5, RMSE on training set: 3.989674827963399.\n",
      "iter: 10, RMSE on training set: 3.9767103102659362.\n",
      "iter: 15, RMSE on training set: 3.9699985436600844.\n",
      "iter: 19, RMSE on training set: 3.9674201344576936.\n",
      "RMSE on test data: 3.971264399836704.\n",
      "Learn the matrix factorization using SGD with K = 50, lambda_i = 0.01, lambda_u = 0.01, num_epochs = 20\n",
      "iter: 0, RMSE on training set: 3.837643355350549.\n",
      "iter: 5, RMSE on training set: 1.1710717132071373.\n",
      "iter: 10, RMSE on training set: 1.0682240095802222.\n",
      "iter: 15, RMSE on training set: 1.0487585995054205.\n",
      "iter: 19, RMSE on training set: 1.0434997026069965.\n",
      "RMSE on test data: 1.0518910603828515.\n",
      "Learn the matrix factorization using SGD with K = 50, lambda_i = 0.01, lambda_u = 0.01, num_epochs = 20\n",
      "iter: 0, RMSE on training set: 1.0209030797944731.\n",
      "iter: 5, RMSE on training set: 0.9951074477987697.\n",
      "iter: 10, RMSE on training set: 0.9909605521450483.\n",
      "iter: 15, RMSE on training set: 0.9900151141574566.\n",
      "iter: 19, RMSE on training set: 0.9898568527757446.\n",
      "RMSE on test data: 0.9994955355511117.\n",
      "Learn the matrix factorization using SGD with K = 50, lambda_i = 0.01, lambda_u = 0.01, num_epochs = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luke/Documents/Projects/ML/project2/MRS/src/SGD_helpers.py:57: RuntimeWarning: overflow encountered in multiply\n",
      "  \n",
      "/Users/luke/Documents/Projects/ML/project2/MRS/src/SGD_helpers.py:58: RuntimeWarning: overflow encountered in multiply\n",
      "  rmse = compute_error(train, user_features, item_features, nz_train)\n",
      "/Users/luke/Documents/Projects/ML/project2/MRS/src/SGD_helpers.py:58: RuntimeWarning: invalid value encountered in subtract\n",
      "  rmse = compute_error(train, user_features, item_features, nz_train)\n",
      "/Users/luke/Documents/Projects/ML/project2/MRS/src/SGD_helpers.py:57: RuntimeWarning: invalid value encountered in add\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0, RMSE on training set: nan.\n",
      "iter: 5, RMSE on training set: nan.\n",
      "iter: 10, RMSE on training set: nan.\n",
      "iter: 15, RMSE on training set: nan.\n",
      "iter: 19, RMSE on training set: nan.\n",
      "RMSE on test data: nan.\n",
      "Learn the matrix factorization using SGD with K = 50, lambda_i = 0.01, lambda_u = 0.01, num_epochs = 20\n",
      "iter: 0, RMSE on training set: nan.\n",
      "iter: 5, RMSE on training set: nan.\n",
      "iter: 10, RMSE on training set: nan.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e13e9f9db273>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0muser_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_MF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Compute SGD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix_factorization_SGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_user\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_item\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Projects/ML/project2/MRS/src/SGD_helpers.py\u001b[0m in \u001b[0;36mmatrix_factorization_SGD\u001b[0;34m(train, test, gamma, num_features, lambda_user, lambda_item, num_epochs, user_feat, item_feat, include_test)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0muser_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mitem_info\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlambda_user\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0muser_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnz_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iter: {}, RMSE on training set: {}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Finding gamma:\n",
    "gammas = np.logspace(-5,-1,5)\n",
    "K = 50\n",
    "lambda_user = 0.01\n",
    "lambda_item = 0.01\n",
    "num_epochs = 20\n",
    "errors = []\n",
    "\n",
    "for gamma in gammas:\n",
    "    # Initialize features matrix\n",
    "    user_init, item_init = init_MF(train, K)\n",
    "    # Compute SGD\n",
    "    _, _, rmse = matrix_factorization_SGD(train, test, gamma, K, lambda_user, lambda_item, num_epochs, user_init, item_init)\n",
    "    errors.append(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After many computations (not only on logspace) for same parameters for K and the 2 lambdas, we found that $\\gamma = 0.025$ is the best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As showed in the following grid, we see that the minimal loss is obtained for parameters $\\lambda_{user} = 0.1$ and $\\lambda_{item} = 0.01$ and number of features $K = 20$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1c788fc03c8>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj4AAAHVCAYAAADxWfFwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQseZw0rBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c79195b588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid = np.matrix([[1.1, 1.0481, 1.007, 1.007],[1.0502, 1.0029, 0.9817, 1.0188],[1.0108, 0.9841, 1.0243, 1.0465],[0.994,0.98577,1.02704,1.0481]])\n",
    "fig, ax = plt.subplots(figsize=(15, 7.5))\n",
    "#cmap = sns.light_palette((260, 75, 60), input=\"husl\", reverse = True)\n",
    "sns.heatmap(grid, ax = ax, square = True, annot = True, linewidth = 0.5, fmt='g')\n",
    "lambdas_is = [1.0, 0.1, 0.01, 0.001]\n",
    "lambdas_us = [1.0, 0.1, 0.01, 0.001]\n",
    "ax.set_xticklabels(lambdas_is)\n",
    "ax.set_yticklabels(lambdas_us)\n",
    "ax.set_xlabel(\"Lambda item\")\n",
    "ax.set_ylabel(\"Lambda user\")\n",
    "plt.title(\"Grid Search for minimal RMSE depending on regularizers lambda user and lambda item\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the SGD with the best parameters we found on the whole ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learn the matrix factorization using SGD with K = 50, gamma = 0.025, lambda_i = 0.01, lambda_u = 0.1, num_epochs = 50\n",
      "iter: 0, RMSE on training set: 1.0496954619678236.\n",
      "iter: 5, RMSE on training set: 0.9983686241195876.\n",
      "iter: 10, RMSE on training set: 0.9524652654562149.\n",
      "iter: 15, RMSE on training set: 0.9302734455252297.\n",
      "iter: 20, RMSE on training set: 0.9215310043111165.\n",
      "iter: 25, RMSE on training set: 0.9181243339190256.\n",
      "iter: 30, RMSE on training set: 0.916771667704421.\n",
      "iter: 35, RMSE on training set: 0.9162301837893795.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-1cc632e84fbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0muser_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_MF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m item_feats_SGD, user_feats_SGD, rmse = matrix_factorization_SGD(ratings, test, best_gamma, K, best_lambda_u, best_lambda_i, num_epochs,\n\u001b[0;32m----> 9\u001b[0;31m                                                                     user_init, item_init, include_test = True)\n\u001b[0m",
      "\u001b[0;32m~/Documents/Projects/ML/project2/MRS/src/SGD_helpers.py\u001b[0m in \u001b[0;36mmatrix_factorization_SGD\u001b[0;34m(train, test, gamma, num_features, lambda_user, lambda_item, num_epochs, user_feat, item_feat, include_test)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0muser_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mitem_info\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlambda_user\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0muser_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnz_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iter: {}, RMSE on training set: {}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Projects/ML/project2/MRS/src/SGD_helpers.py\u001b[0m in \u001b[0;36mcompute_error\u001b[0;34m(data, user_features, item_features, nz)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnz\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mitem_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0muser_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mmse\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0muser_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmse\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_gamma = 0.025\n",
    "best_lambda_u = 0.1\n",
    "best_lambda_i = 0.01\n",
    "K = 50\n",
    "num_epochs = 50\n",
    "\n",
    "user_init, item_init = init_MF(ratings, K)\n",
    "item_feats_SGD, user_feats_SGD, rmse = matrix_factorization_SGD(ratings, test, best_gamma, K, best_lambda_u, best_lambda_i, num_epochs,\n",
    "                                                                    user_init, item_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempt_dir = '../tempt/'\n",
    "with open(tempt_dir + 'item_feats_SGD.pk','wb') as f:\n",
    "    pickle.dump(item_feats_SGD, f)\n",
    "with open(tempt_dir + 'user_feats_SGD.pk','wb') as f:\n",
    "    pickle.dump(user_feats_SGD, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempt_dir = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tempt_dir + 'user_feats_SGD.pk','rb') as f:\n",
    "    user_feats_SGD = pickle.load(f)\n",
    "with open(tempt_dir + 'item_feats_SGD.pk','rb') as f:\n",
    "    item_feats_SGD = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of predictions (user x items): (1000, 10000)\n"
     ]
    }
   ],
   "source": [
    "predictions = np.dot(item_feats_SGD.T, user_feats_SGD)\n",
    "print(\"Shape of predictions (user x items): {}\".format(np.shape(predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MF_helpers import get_bias_train, get_bias_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of having $p_{u, i} = \\mathbf{w}_i\\mathbf{z^{T}}_u$ we would add bias on the user and item by having the following:\n",
    "$$p_{u, i} = \\mu + b_{u} + b_{i} + \\mathbf{w}_i\\mathbf{z^{T}}_u$$\n",
    "\n",
    "where $\\mu$ is the average of all ratings, $b_{u}$ and $b_{i}$ are the observed deviations of user u and item i respectively from the average (the biases).\n",
    "\n",
    "Thus we now want to find the best $\\mathbf{W}$ and $\\mathbf{Z}$ that minimizes the loss:\n",
    "\n",
    "$$min_{W,Z} \\sum_{(u, i) \\in \\Omega} (r_{u,i} - \\mu - b_{u} - b_{i} - \\mathbf{W_{u}} \\mathbf{Z^{T}_{i}}) + \\lambda_{item} (||W||_{F}^{2} + b_{i}^{2}) + \\lambda_{user} (||Z||_{F}^{2} + b_{u}^{2}) $$\n",
    "\n",
    "And we need to compute the gradient of this loss. It is the same as before except we can convert our rating matrix to a biased rating matrix with ratings $r'_{u, i} = r_{u, i} - \\mu - b_{u} - b_{i}$ and compute our SGD on this biased matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_train, total_bias, bias_u_train, bias_i_train = get_bias_train(train) #ratings for final submissions\n",
    "bias_test = get_bias_test(test, total_bias, bias_u_train, bias_i_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute grid search with best parameters (here just with K = 20 features):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 20, lambda_u = 1.0, lambda_i = 1.0\n",
      "learn the matrix factorization using SGD...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-90d43f3ad3fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"K = {}, lambda_u = {}, lambda_i = {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         item_feats, user_feats, rmse = matrix_factorization_SGD(bias_train, bias_test, gamma, K, lambda_i,\n\u001b[0;32m---> 19\u001b[0;31m                                                                  lambda_u, num_epochs, user_init, item_init)\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;31m### For warm start, we keep the user_features and item_features that gave us the minimal rmse previously computed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrmse\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmin_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Projects/ML/project2/MRS/src/SGD_helpers.py\u001b[0m in \u001b[0;36mmatrix_factorization_SGD\u001b[0;34m(train, test, gamma, num_features, lambda_user, lambda_item, num_epochs, user_features, item_features)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;31m# calculate the gradient and update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mitem_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0muser_info\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlambda_item\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mitem_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0muser_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mitem_info\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlambda_user\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0muser_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Grid Search:\n",
    "grid = np.zeros((4, 4)) ### np.zeros((4, 4, 4))\n",
    "gamma = 0.025 # best gamma we found above\n",
    "num_epochs = 5\n",
    "lambdas_user = np.logspace(-3,0,4)[::-1] #From max to min\n",
    "lambdas_item = np.logspace(-3,0,4)[::-1]\n",
    "K = 20\n",
    "\n",
    "min_loss = 100000\n",
    "best_user_feats = []\n",
    "best_item_feats = []\n",
    "\n",
    "### Warm start: directly start computation from previously computed item_features and user_features and not random initialization\n",
    "user_init, item_init = init_MF(bias_train, K)\n",
    "for x,lambda_u in enumerate(lambdas_user):\n",
    "    for y,lambda_i in enumerate(lambdas_item):\n",
    "        print(\"K = {}, lambda_u = {}, lambda_i = {}\".format(int(K), lambda_u, lambda_i))\n",
    "        item_feats, user_feats, rmse = matrix_factorization_SGD(bias_train, bias_test, gamma, K, lambda_i,\n",
    "                                                                 lambda_u, num_epochs, user_init, item_init)\n",
    "        ### For warm start, we keep the user_features and item_features that gave us the minimal rmse previously computed\n",
    "        if rmse < min_loss:\n",
    "            print(\"New best\")\n",
    "            min_loss = rmse\n",
    "            user_init = user_feats\n",
    "            item_init = item_feats\n",
    "            best_user_feats = np.copy(user_feats)\n",
    "            best_item_feats = np.copy(item_feats)\n",
    "        grid[x, y] = rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute SGD with the best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learn the matrix factorization using SGD...\n",
      "iter: 0, RMSE on training set: 0.9940081486805841.\n",
      "RMSE on test data: 3.972585932783249.\n"
     ]
    }
   ],
   "source": [
    "# define parameters\n",
    "gamma = 0.025\n",
    "K = 20\n",
    "lambda_user = 0.1 \n",
    "lambda_item = 0.001\n",
    "num_epochs = 1\n",
    "user_init, item_init = init_MF(bias_train, K)\n",
    "\n",
    "item_featuresSGD, user_featuresSGD, rmse = matrix_factorization_SGD(bias_train, bias_test, gamma, K, lambda_user, lambda_item, num_epochs, user_init, item_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempt_dir = '../tempt/'\n",
    "with open(tempt_dir + 'item_featuresSGD.pk','wb') as f:\n",
    "    pickle.dump(item_featuresSGD, f)\n",
    "with open(tempt_dir + 'user_featuresSGD.pk','wb') as f:\n",
    "    pickle.dump(user_featuresSGD, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "tempt_dir = './'\n",
    "with open(tempt_dir + 'user_features_bias.pk','rb') as f:\n",
    "    user_featuresSGD = pickle.load(f)\n",
    "    \n",
    "with open(tempt_dir + 'item_features_bias.pk','rb') as f:\n",
    "    item_featuresSGD = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10000)\n",
      "(1000, 10000)\n",
      "(1000, 10000)\n",
      "(1000, 10000)\n",
      "Shape of predictions (user x items): (1000, 10000)\n"
     ]
    }
   ],
   "source": [
    "from MF_helpers import predict_with_bias, predict_no_bias\n",
    "\n",
    "# Compute predictions matrix from the biases, item and user features computed with SGD\n",
    "predictions = predict_with_bias(item_featuresSGD, user_featuresSGD,mean, bias_u_train, bias_i_train)\n",
    "print(\"Shape of predictions (user x items): {}\".format(np.shape(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 37\n",
      "3.9174388550028096\n"
     ]
    }
   ],
   "source": [
    "### Checking if results appear the same in the final excel file\n",
    "first_user, first_item = sample_ids[0][0],sample_ids[0][1]\n",
    "print(first_item, first_user)\n",
    "print(predictions[first_user - 1, first_item - 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to set the ratings above 5.0 to 5.0 and those below 1.0 to 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum prediction: 1.0, Maximum prediction: 5.0\n"
     ]
    }
   ],
   "source": [
    "predictions[ np.where( predictions > 5.0 ) ] = 5.0\n",
    "predictions[ np.where(predictions < 1.0)] = 1.0\n",
    "print(\"Minimum prediction: {}, Maximum prediction: {}\".format(np.min(predictions), np.max(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of predictions (user x items): (1000, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of predictions (user x items): {}\".format(np.shape(predictions)))\n",
    "wanted_preds = getWantedPredictions(predictions.T, sample_ids)\n",
    "create_csv_submission(sample_ids, np.round(wanted_preds), sub_dir + \"bias_FULL_best_param_50epochs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../submit/'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
